{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e200adb1",
   "metadata": {},
   "source": [
    "# 빅데이터와 금융자료분석 팀프로젝트\n",
    "\n",
    "XGboost 알고리즘을 활용한 은행 대출의 부도 여부 예측 모델 구축\n",
    "\n",
    "강상묵(20259013) / 김형환(20249132) / 유석호(20249264) / 이현준(20249349) / 최영서(20249430) / 최재필(20249433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581feb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 모음\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 난수 생성기에 일관된 시드 설정\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# 결과 저장을 위한 디렉토리 생성\n",
    "os.makedirs('model_results', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)  # plots 디렉토리 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3f18d",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 및 데이터 확인\n",
    "12개의 수치형변수와 15개의 문자형 변수(목적변수 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277f811",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396030 entries, 0 to 396029\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   loan_amnt             396030 non-null  float64\n",
      " 1   term                  396030 non-null  object \n",
      " 2   int_rate              396030 non-null  float64\n",
      " 3   installment           396030 non-null  float64\n",
      " 4   grade                 396030 non-null  object \n",
      " 5   sub_grade             396030 non-null  object \n",
      " 6   emp_title             373103 non-null  object \n",
      " 7   emp_length            377729 non-null  object \n",
      " 8   home_ownership        396030 non-null  object \n",
      " 9   annual_inc            396030 non-null  float64\n",
      " 10  verification_status   396030 non-null  object \n",
      " 11  issue_d               396030 non-null  object \n",
      " 12  loan_status           396030 non-null  object \n",
      " 13  purpose               396030 non-null  object \n",
      " 14  title                 394274 non-null  object \n",
      " 15  dti                   396030 non-null  float64\n",
      " 16  earliest_cr_line      396030 non-null  object \n",
      " 17  open_acc              396030 non-null  float64\n",
      " 18  pub_rec               396030 non-null  float64\n",
      " 19  revol_bal             396030 non-null  float64\n",
      " 20  revol_util            395754 non-null  float64\n",
      " 21  total_acc             396030 non-null  float64\n",
      " 22  initial_list_status   396030 non-null  object \n",
      " 23  application_type      396030 non-null  object \n",
      " 24  mort_acc              358235 non-null  float64\n",
      " 25  pub_rec_bankruptcies  395495 non-null  float64\n",
      " 26  address               396030 non-null  object \n",
      "dtypes: float64(12), object(15)\n",
      "memory usage: 81.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 불러오기 및 데이터 확인 : 12개의 수치형변수와 15개의 문자형 변수(목적변수 포함)\n",
    "data = pd.read_csv(\"data/lending_club_loan_two.csv\")\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18a56d",
   "metadata": {},
   "source": [
    "### 클래스 불균형 및 변수간 상관관계 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 불균형 시각화 : 목적변수는 약 8:2로 불균형 존재\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=data['loan_status'])\n",
    "plt.title(\"Class Imbalance\")\n",
    "plt.savefig('plots/class_imbalance.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347cb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터간 상관관계 행렬 그리기 : 일부 변수에 높은 상관관계가 존재하는 것을 확인\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "\n",
    "sns.heatmap(numeric_data.corr(), annot=True, cmap='viridis')\n",
    "plt.title(\"Correlation Matrix of Numeric Features\")\n",
    "plt.savefig('plots/correlation_matrix.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c47040",
   "metadata": {},
   "source": [
    "### 주요 변수별 목적변수 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b819912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신용점수별 목적변수의 분포 확인 : 낮은 등급일수록 부도율 높음\n",
    "fully_paid = data.loc[data['loan_status'] == 'Fully Paid', 'sub_grade'].value_counts().sort_index()\n",
    "charged_off = data.loc[data['loan_status'] == 'Charged Off', 'sub_grade'].value_counts().sort_index()\n",
    "\n",
    "grades = sorted(set(fully_paid.index).union(set(charged_off.index)))\n",
    "\n",
    "x = range(len(grades))\n",
    "width = 0.35  # bar 폭\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar([i - width/2 for i in x], fully_paid.reindex(grades, fill_value=0), width=width, label='Fully Paid')\n",
    "ax.bar([i + width/2 for i in x], charged_off.reindex(grades, fill_value=0), width=width, label='Charged Off')\n",
    "\n",
    "ax.set_xlabel('Grades')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Loan Status by Grade')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(grades)\n",
    "ax.legend()\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/loan_status_by_grade.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5dbf458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2559250719.py:15: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=90)\n"
     ]
    }
   ],
   "source": [
    "# 대출기간, 집보유여부 등 주요 변수에 대한 목적변수 분포 확인\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "sns.countplot(x='term', data=data, hue='loan_status')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "sns.countplot(x='home_ownership', data=data, hue='loan_status')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "sns.countplot(x='verification_status', data=data, hue='loan_status')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "g = sns.countplot(x='purpose', data=data, hue='loan_status')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.savefig('plots/loan_status_by_features.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1def9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                        2\n",
       "grade                       7\n",
       "sub_grade                  35\n",
       "emp_title              173105\n",
       "emp_length                 11\n",
       "home_ownership              6\n",
       "verification_status         3\n",
       "issue_d                   115\n",
       "loan_status                 2\n",
       "purpose                    14\n",
       "title                   48816\n",
       "earliest_cr_line          684\n",
       "initial_list_status         2\n",
       "application_type            3\n",
       "address                393700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자형 변수 고유값 개수 출력 : 일부 변수에 과도하게 많은 고유값 확인\n",
    "categorical_columns = data.select_dtypes(include='object')\n",
    "categorical_columns.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acf0c8",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427d8c6",
   "metadata": {},
   "source": [
    "### 변수를 분석에 적합하도록 변환, 삭제 등 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7e4c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 데이터 전처리\n",
    "# 주소는 우편번호만 추출\n",
    "data['zip_code'] = data.address.apply(lambda x: x[-5:])\n",
    "data['zip_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21474f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396030 entries, 0 to 396029\n",
      "Data columns (total 45 columns):\n",
      " #   Column                               Non-Null Count   Dtype  \n",
      "---  ------                               --------------   -----  \n",
      " 0   loan_amnt                            396030 non-null  float64\n",
      " 1   term                                 396030 non-null  int64  \n",
      " 2   int_rate                             396030 non-null  float64\n",
      " 3   installment                          396030 non-null  float64\n",
      " 4   sub_grade                            396030 non-null  int32  \n",
      " 5   annual_inc                           396030 non-null  float64\n",
      " 6   loan_status                          396030 non-null  int32  \n",
      " 7   dti                                  396030 non-null  float64\n",
      " 8   open_acc                             396030 non-null  float64\n",
      " 9   pub_rec                              396030 non-null  float64\n",
      " 10  revol_bal                            396030 non-null  float64\n",
      " 11  revol_util                           395754 non-null  float64\n",
      " 12  total_acc                            396030 non-null  float64\n",
      " 13  mort_acc                             358235 non-null  float64\n",
      " 14  pub_rec_bankruptcies                 395495 non-null  float64\n",
      " 15  home_ownership_OTHER                 396030 non-null  bool   \n",
      " 16  home_ownership_OWN                   396030 non-null  bool   \n",
      " 17  home_ownership_RENT                  396030 non-null  bool   \n",
      " 18  verification_status_Source Verified  396030 non-null  bool   \n",
      " 19  verification_status_Verified         396030 non-null  bool   \n",
      " 20  purpose_credit_card                  396030 non-null  bool   \n",
      " 21  purpose_debt_consolidation           396030 non-null  bool   \n",
      " 22  purpose_educational                  396030 non-null  bool   \n",
      " 23  purpose_home_improvement             396030 non-null  bool   \n",
      " 24  purpose_house                        396030 non-null  bool   \n",
      " 25  purpose_major_purchase               396030 non-null  bool   \n",
      " 26  purpose_medical                      396030 non-null  bool   \n",
      " 27  purpose_moving                       396030 non-null  bool   \n",
      " 28  purpose_other                        396030 non-null  bool   \n",
      " 29  purpose_renewable_energy             396030 non-null  bool   \n",
      " 30  purpose_small_business               396030 non-null  bool   \n",
      " 31  purpose_vacation                     396030 non-null  bool   \n",
      " 32  purpose_wedding                      396030 non-null  bool   \n",
      " 33  initial_list_status_w                396030 non-null  bool   \n",
      " 34  application_type_INDIVIDUAL          396030 non-null  bool   \n",
      " 35  application_type_JOINT               396030 non-null  bool   \n",
      " 36  zip_code_05113                       396030 non-null  bool   \n",
      " 37  zip_code_11650                       396030 non-null  bool   \n",
      " 38  zip_code_22690                       396030 non-null  bool   \n",
      " 39  zip_code_29597                       396030 non-null  bool   \n",
      " 40  zip_code_30723                       396030 non-null  bool   \n",
      " 41  zip_code_48052                       396030 non-null  bool   \n",
      " 42  zip_code_70466                       396030 non-null  bool   \n",
      " 43  zip_code_86630                       396030 non-null  bool   \n",
      " 44  zip_code_93700                       396030 non-null  bool   \n",
      "dtypes: bool(30), float64(12), int32(2), int64(1)\n",
      "memory usage: 53.6 MB\n"
     ]
    }
   ],
   "source": [
    "# 집 소유여부에서 극소수의 경우 제외\n",
    "data.loc[(data.home_ownership == 'ANY') | (data.home_ownership == 'NONE'), 'home_ownership'] = 'OTHER'  \n",
    "\n",
    "# 대출건별로 모두 달라 고유값이 너무 많거나(100개 이상), 다른 변수로부터 추출할수있는 등 불필요한 열 제거\n",
    "drop_cols = ['emp_title', 'emp_length', 'grade', 'title', 'address', 'issue_d', 'earliest_cr_line']\n",
    "data.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# 대출개월수는 수치형으로 변환\n",
    "term_values = {' 36 months': 36, ' 60 months': 60}\n",
    "data['term'] = data.term.map(term_values)\n",
    "\n",
    "# 문자형변수 변환 : 라벨인코딩, 원핫인코딩\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 목적변수 (loan_status) 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "data['loan_status'] = label_encoder.fit_transform(data['loan_status'])\n",
    "\n",
    "# sub_grade 라벨 인코딩 : 평가등급은 순서가 있음\n",
    "data['sub_grade'] = label_encoder.fit_transform(data['sub_grade'])\n",
    "\n",
    "# 나머지 문자형 변수들 원핫 인코딩\n",
    "categorical_columns = data.select_dtypes(include='object').columns\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16704b1",
   "metadata": {},
   "source": [
    "### 훈련/평가데이터 분할\n",
    "\n",
    "목적변수의 불균형이 존재하므로, 분할 시 **계층적 샘플링(Stratified Sampling)**을 적용\n",
    "\n",
    "이는 각 분할 세트에서 클래스 비율이 원본 데이터셋과 동일하게 유지되도록 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1649034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 클래스 분포:\n",
      "loan_status\n",
      "1    0.803871\n",
      "0    0.196129\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "훈련 데이터 클래스 분포:\n",
      "loan_status\n",
      "1    0.803871\n",
      "0    0.196129\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "테스트 데이터 클래스 분포:\n",
      "loan_status\n",
      "1    0.80387\n",
      "0    0.19613\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 훈련/평가데이터 분할 : 7대3로 분할 (계층적 샘플링 적용)\n",
    "X = data.drop(columns=['loan_status']) \n",
    "y = data['loan_status']\n",
    "\n",
    "# stratify=y 매개변수를 추가하여 계층적 샘플링 적용\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 분할 후 클래스 비율 확인\n",
    "print(\"원본 데이터 클래스 분포:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n훈련 데이터 클래스 분포:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n테스트 데이터 클래스 분포:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017ee5d",
   "metadata": {},
   "source": [
    "### 결측치 및 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 결측값 및 이상치 처리 (중간값 + Isolation Forest)\n",
    "# 수치형 변수의 결측값을 중간값으로 처리\n",
    "X_train_fillna = X_train.copy().fillna(X_train.median())\n",
    "\n",
    "X_train_numeric = X_train_fillna.select_dtypes(include='number')\n",
    "original_len = len(X_train_numeric)\n",
    "\n",
    "# 이상치 탐지 및 제거 (수치형 변수에 대해서만 1% 제거)\n",
    "iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso.fit_predict(X_train_numeric)\n",
    "\n",
    "# 이상치가 아닌 데이터만 선택\n",
    "X_train_clean = X_train_fillna[outliers == 1]\n",
    "y_train_clean = y_train[outliers == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c691c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대출 규모와 DTI를 이용하여 이상치 시각화\n",
    "columns = ['loan_amnt', 'dti']\n",
    "X_viz = X_train[columns].copy()\n",
    "\n",
    "X_outliers = X_viz.loc[outliers == -1]\n",
    "X_clean = X_viz.loc[outliers == 1]\n",
    "\n",
    "# 2D 시각화\n",
    "X_clean_sample = X_clean.sample(n=3000, random_state=42)\n",
    "X_outliers_sample = X_outliers.sample(n=50, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.scatter(X_clean_sample['loan_amnt'], X_clean_sample['dti'],\n",
    "            c='black', label='Inliers', alpha=0.5, s=10)\n",
    "plt.scatter(X_outliers_sample['loan_amnt'], X_outliers_sample['dti'],\n",
    "            c='red', label='Outliers', alpha=0.7, s=10)\n",
    "\n",
    "plt.xlabel('Loan Amount')\n",
    "plt.ylabel('Debt-to-Income Ratio (DTI)')\n",
    "plt.title('Isolation Forest Outlier Detection (2D)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/isolation_forest_outlier_detection_2d.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e158e",
   "metadata": {},
   "source": [
    "### TSNE를 이용한 차원 축소 및 이상치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e106d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TSNE를 이용한 이상치 시각화 분석 : 기존 정보로는 시각화 한계가 있어 차원축소 적용\n",
    "\n",
    "# 수치형 데이터만 추출(약 1만개)하여 T-SNE로 3차원 축소\n",
    "X_tsne_input_clean = X_train_numeric[outliers==1].sample(n=1000,random_state=42).select_dtypes(include='number')\n",
    "X_tsne_input_outliers = X_train_numeric[outliers==-1].sample(n=20,random_state=42).select_dtypes(include='number')\n",
    "X_tsne_input = pd.concat([X_tsne_input_clean,X_tsne_input_outliers], axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_tsne_input)\n",
    "\n",
    "# 시각화\n",
    "labels = np.array([1]*1000 + [-1]*20)\n",
    "tsne_df = pd.DataFrame(X_tsne, columns=['x', 'y', 'z'])\n",
    "tsne_df['outlier'] = labels\n",
    "\n",
    "inliers = tsne_df[tsne_df['outlier'] == 1]\n",
    "outliers_df = tsne_df[tsne_df['outlier'] == -1]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(inliers['x'], inliers['y'], inliers['z'],\n",
    "           c='black', label='Inliers', alpha=0.5, s=10)\n",
    "ax.scatter(outliers_df['x'], outliers_df['y'], outliers_df['z'],\n",
    "           c='red', label='Outliers', alpha=0.7, s=15)\n",
    "\n",
    "ax.set_title('3D t-SNE Visualization of Isolation Forest Outliers')\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "ax.legend()\n",
    "plt.savefig('plots/tsne_visualization.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27eca5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬 시각화\n",
    "X_clean_sample = X_clean.sample(n=10000, random_state=42)\n",
    "X_outliers_sample = X_outliers.sample(n=200, random_state=42)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.scatter(X_clean_sample['loan_amnt'], X_clean_sample['dti'],\n",
    "            c='black', label='Inliers', alpha=0.5, s=10)\n",
    "ax1.scatter(X_outliers_sample['loan_amnt'], X_outliers_sample['dti'],\n",
    "            c='red', label='Outliers', alpha=0.7, s=10)\n",
    "ax1.set_xlabel('Loan Amount')\n",
    "ax1.set_ylabel('Debt-to-Income Ratio (DTI)')\n",
    "ax1.set_title('2D Scatter of Outliers')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax2.scatter(tsne_df[tsne_df['outlier'] == 1]['x'],\n",
    "            tsne_df[tsne_df['outlier'] == 1]['y'],\n",
    "            tsne_df[tsne_df['outlier'] == 1]['z'],\n",
    "            c='black', label='Inliers', alpha=0.5, s=10)\n",
    "ax2.scatter(tsne_df[tsne_df['outlier'] == -1]['x'],\n",
    "            tsne_df[tsne_df['outlier'] == -1]['y'],\n",
    "            tsne_df[tsne_df['outlier'] == -1]['z'],\n",
    "            c='red', label='Outliers', alpha=0.7, s=15)\n",
    "ax2.set_title('3D t-SNE of Outliers')\n",
    "ax2.set_xlabel('t-SNE 1')\n",
    "ax2.set_ylabel('t-SNE 2')\n",
    "ax2.set_zlabel('t-SNE 3')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/tsne_of_outliers.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02650d61",
   "metadata": {},
   "source": [
    "## Boruta 알고리즘을 활용한 변수선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8ff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 / 15\n",
      "Iteration: 2 / 15\n",
      "Iteration: 3 / 15\n",
      "Iteration: 4 / 15\n",
      "Iteration: 5 / 15\n",
      "Iteration: 6 / 15\n",
      "Iteration: 7 / 15\n",
      "Iteration: 8 / 15\n",
      "Iteration: 9 / 15\n",
      "Iteration: 10 / 15\n",
      "Iteration: 11 / 15\n",
      "Iteration: 12 / 15\n",
      "Iteration: 13 / 15\n",
      "Iteration: 14 / 15\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t15 / 15\n",
      "Confirmed: \t10\n",
      "Tentative: \t2\n",
      "Rejected: \t2\n",
      "Number of selected features(Non-onehot): 10\n",
      "['loan_amnt', 'term', 'int_rate', 'installment', 'sub_grade', 'annual_inc', 'dti', 'revol_bal', 'revol_util', 'mort_acc']\n"
     ]
    }
   ],
   "source": [
    "# 5. Boruta 알고리즘을 활용한 변수선택 \n",
    "\n",
    "# 원핫 인코딩된 변수 식별\n",
    "onehot_columns = X_train_clean.select_dtypes(include='bool').columns.tolist()\n",
    "\n",
    "# 수치형 + 라벨 인코딩된 변수 선택\n",
    "X_boruta = X_train_clean.drop(columns=onehot_columns)\n",
    "y_boruta = y_train_clean.copy()\n",
    "\n",
    "# Boruta 알고리즘 적용\n",
    "rf = RandomForestClassifier(max_depth=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "np.int = np.int64\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n",
    "\n",
    "brtfs = BorutaPy(estimator=rf,n_estimators=7,verbose=1,random_state=42,max_iter=15,alpha=0.01)\n",
    "brtfs.fit(X_boruta.values, y_boruta.values)\n",
    "\n",
    "selected_features = X_boruta.columns[brtfs.support_].tolist()    \n",
    "X_selected = X_boruta[selected_features]\n",
    "X_onehot = X_train_clean[onehot_columns]\n",
    "print(f\"Number of selected features(Non-onehot): {len(selected_features)}\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727147f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 274448 entries, 214484 to 257563\n",
      "Data columns (total 40 columns):\n",
      " #   Column                               Non-Null Count   Dtype  \n",
      "---  ------                               --------------   -----  \n",
      " 0   loan_amnt                            274448 non-null  float64\n",
      " 1   term                                 274448 non-null  int64  \n",
      " 2   int_rate                             274448 non-null  float64\n",
      " 3   installment                          274448 non-null  float64\n",
      " 4   sub_grade                            274448 non-null  int32  \n",
      " 5   annual_inc                           274448 non-null  float64\n",
      " 6   dti                                  274448 non-null  float64\n",
      " 7   revol_bal                            274448 non-null  float64\n",
      " 8   revol_util                           274448 non-null  float64\n",
      " 9   mort_acc                             274448 non-null  float64\n",
      " 10  home_ownership_OTHER                 274448 non-null  bool   \n",
      " 11  home_ownership_OWN                   274448 non-null  bool   \n",
      " 12  home_ownership_RENT                  274448 non-null  bool   \n",
      " 13  verification_status_Source Verified  274448 non-null  bool   \n",
      " 14  verification_status_Verified         274448 non-null  bool   \n",
      " 15  purpose_credit_card                  274448 non-null  bool   \n",
      " 16  purpose_debt_consolidation           274448 non-null  bool   \n",
      " 17  purpose_educational                  274448 non-null  bool   \n",
      " 18  purpose_home_improvement             274448 non-null  bool   \n",
      " 19  purpose_house                        274448 non-null  bool   \n",
      " 20  purpose_major_purchase               274448 non-null  bool   \n",
      " 21  purpose_medical                      274448 non-null  bool   \n",
      " 22  purpose_moving                       274448 non-null  bool   \n",
      " 23  purpose_other                        274448 non-null  bool   \n",
      " 24  purpose_renewable_energy             274448 non-null  bool   \n",
      " 25  purpose_small_business               274448 non-null  bool   \n",
      " 26  purpose_vacation                     274448 non-null  bool   \n",
      " 27  purpose_wedding                      274448 non-null  bool   \n",
      " 28  initial_list_status_w                274448 non-null  bool   \n",
      " 29  application_type_INDIVIDUAL          274448 non-null  bool   \n",
      " 30  application_type_JOINT               274448 non-null  bool   \n",
      " 31  zip_code_05113                       274448 non-null  bool   \n",
      " 32  zip_code_11650                       274448 non-null  bool   \n",
      " 33  zip_code_22690                       274448 non-null  bool   \n",
      " 34  zip_code_29597                       274448 non-null  bool   \n",
      " 35  zip_code_30723                       274448 non-null  bool   \n",
      " 36  zip_code_48052                       274448 non-null  bool   \n",
      " 37  zip_code_70466                       274448 non-null  bool   \n",
      " 38  zip_code_86630                       274448 non-null  bool   \n",
      " 39  zip_code_93700                       274448 non-null  bool   \n",
      "dtypes: bool(30), float64(8), int32(1), int64(1)\n",
      "memory usage: 29.8 MB\n"
     ]
    }
   ],
   "source": [
    "# 최종 훈련데이터 가공 완료\n",
    "X_train_brtfs = pd.concat([X_selected, X_onehot], axis=1)\n",
    "X_train_brtfs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42735b52",
   "metadata": {},
   "source": [
    "## 모델 구축 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415bfb8",
   "metadata": {},
   "source": [
    "### 클래스 불균형 문제 및 교차 검증 개선\n",
    "\n",
    "표본의 수 및 칼럼의 수가 그리 많지 않으므로 Oversampling을 통해 클래스 불균형을 해소.\n",
    "\n",
    "ADASYN 적용시 아래와 같은 문제가 발생할 수 있으므로, **imblearn.pipeline**을 사용하여 Oversampling 적용\n",
    "\n",
    "1. **검증 무결성 이슈 (Validation Integrity Issue)**: ADASYN으로 생성된 합성 데이터가 교차 검증(CV) 과정에서 훈련 및 검증 폴드에 모두 포함\n",
    "\n",
    "2. **과대평가된 성능 지표 (Inflated Performance Metrics)**: 검증 세트에 합성 데이터가 포함되면, 모델은 사실상 훈련 데이터의 변형된 버전으로 평가되어 성능이 과대평가\n",
    "\n",
    "3. **과적합 위험 (Overfitting Risk)**: 합성 데이터로 검증하면 모델이 실제 데이터에 대한 일반화 능력 대신 합성 패턴을 학습할 위험\n",
    "\n",
    "**imblearn.pipeline**을 사용시 교차 검증의 각 폴드 내에서만 오버샘플링이 적용되므로,\n",
    "\n",
    "- 각 CV 폴드의 **훈련 데이터에만** ADASYN이 적용됨\n",
    "- 검증은 항상 **원본 데이터**로만 수행됨\n",
    "- 모델의 실제 성능을 더 정확하게 평가할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2724aea",
   "metadata": {},
   "source": [
    "### XGBoost 모델 최적화 이단계 접근법\n",
    "\n",
    "XGBoost 모델의 하이퍼파라미터 튜닝에 이단계 접근법(Two-Step Optimization)을 적용:\n",
    "\n",
    "**1단계: 초기 하이퍼파라미터 탐색**\n",
    "- 상대적으로 높은 학습률(0.1)과 고정된 n_estimators 값으로 하이퍼파라미터 조합을 탐색\n",
    "- 각 하이퍼파라미터 조합이 동일한 학습 기회(같은 트리 개수)를 갖도록 보장\n",
    "- 교차 검증 내에서 ADASYN 오버샘플링을 정확히 적용\n",
    "\n",
    "**2단계: 최적 모델 미세 조정**\n",
    "- 1단계에서 찾은 최적 하이퍼파라미터에 낮은 학습률(0.01)과 높은 n_estimators(10000) 적용\n",
    "- early_stopping_rounds를 사용하여 최적의 트리 개수 결정\n",
    "- 전체 훈련 데이터와 검증 데이터를 사용하여 최종 모델 학습\n",
    "\n",
    "**이러한 접근법의 이점:**\n",
    "- 공정한 하이퍼파라미터 비교: 1단계에서 모든 조합이 동일한 tree 개수로 평가됨\n",
    "- 과적합 방지: 낮은 학습률과 early stopping으로 모델 안정성 향상\n",
    "- 계산 효율성: 미세 조정은 최적 하이퍼파라미터 조합에만 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f55d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 하이퍼파라미터 검색 결과를 불러옵니다...\n",
      "최적 하이퍼파라미터:\n",
      "{'classifier__subsample': 1.0, 'classifier__reg_lambda': 5, 'classifier__reg_alpha': 0.1, 'classifier__n_estimators': 100, 'classifier__min_child_weight': 0.1, 'classifier__max_depth': 7, 'classifier__gamma': 1, 'classifier__colsample_bytree': 1.0}\n",
      "최고 F1 점수 (CV): 0.9354467284124377\n",
      "\n",
      "상위 5개 하이퍼파라미터 조합:\n",
      "                                               params  mean_test_score  \\\n",
      "12  {'classifier__subsample': 1.0, 'classifier__re...         0.935447   \n",
      "16  {'classifier__subsample': 1.0, 'classifier__re...         0.935357   \n",
      "2   {'classifier__subsample': 1.0, 'classifier__re...         0.935325   \n",
      "19  {'classifier__subsample': 0.8, 'classifier__re...         0.935320   \n",
      "4   {'classifier__subsample': 0.8, 'classifier__re...         0.935289   \n",
      "\n",
      "    std_test_score  rank_test_score  \n",
      "12        0.000453                1  \n",
      "16        0.000471                2  \n",
      "2         0.000426                3  \n",
      "19        0.000461                4  \n",
      "4         0.000449                5  \n"
     ]
    }
   ],
   "source": [
    "# 1단계: 초기 하이퍼파라미터 탐색 - 높은 학습률로 여러 조합 탐색\n",
    "\n",
    "# 하이퍼파라미터 검색 결과를 저장할 경로 설정\n",
    "hp_search_results_path = 'model_results/hp_search_results.pkl'\n",
    "\n",
    "# 이미 저장된 하이퍼파라미터 결과가 있는지 확인\n",
    "if os.path.exists(hp_search_results_path):\n",
    "    print(\"저장된 하이퍼파라미터 검색 결과를 불러옵니다...\")\n",
    "    with open(hp_search_results_path, 'rb') as f:\n",
    "        step1_search = pickle.load(f)\n",
    "    \n",
    "    print(\"최적 하이퍼파라미터:\")\n",
    "    print(step1_search.best_params_)\n",
    "    print(\"최고 F1 점수 (CV):\", step1_search.best_score_)\n",
    "    \n",
    "    # 상위 5개 하이퍼파라미터 조합 확인\n",
    "    step1_results = pd.DataFrame(step1_search.cv_results_)\n",
    "    columns = ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "    top_5_params = step1_results[columns].sort_values('rank_test_score').head(5)\n",
    "    print(\"\\n상위 5개 하이퍼파라미터 조합:\")\n",
    "    print(top_5_params)\n",
    "else:\n",
    "    # ADASYN을 파이프라인 내에서 적용하여 교차 검증 시 검증 데이터 무결성 유지\n",
    "    step1_pipeline = ImbPipeline([\n",
    "        ('sampler', ADASYN(random_state=42)),\n",
    "        ('classifier', XGBClassifier(eval_metric='logloss', random_state=42, learning_rate=0.1))\n",
    "    ])\n",
    "    \n",
    "    # 하이퍼파라미터 설정 - 고정된 n_estimators로 공정한 비교 보장\n",
    "    param_dist = {\n",
    "        'classifier__n_estimators': [100, 300, 500],  # 고정된 값으로 탐색\n",
    "        'classifier__max_depth': [3, 5, 7, 9],\n",
    "        'classifier__min_child_weight': [0, 0.1, 0.3, 0.5],\n",
    "        'classifier__gamma': [0, 0.1, 1],\n",
    "        'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "        'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'classifier__reg_alpha': [0, 0.1, 1],\n",
    "        'classifier__reg_lambda': [1, 5, 10]\n",
    "    }\n",
    "    \n",
    "    # RandomizedSearchCV - 각 CV 폴드 내에서 올바르게 ADASYN 적용\n",
    "    step1_search = RandomizedSearchCV(\n",
    "        estimator=step1_pipeline,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=25,  # 계산 자원에 따라 조정 가능\n",
    "        scoring='f1',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 1단계 모델 훈련\n",
    "    print(\"1단계: 초기 하이퍼파라미터 탐색 중...\")\n",
    "    step1_search.fit(X_train_brtfs, y_train_clean)\n",
    "    \n",
    "    # 최적 하이퍼파라미터 출력\n",
    "    print(\"최적 하이퍼파라미터:\")\n",
    "    print(step1_search.best_params_)\n",
    "    print(\"최고 F1 점수 (CV):\", step1_search.best_score_)\n",
    "    \n",
    "    # 상위 5개 하이퍼파라미터 조합 확인\n",
    "    step1_results = pd.DataFrame(step1_search.cv_results_)\n",
    "    columns = ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "    top_5_params = step1_results[columns].sort_values('rank_test_score').head(5)\n",
    "    print(\"\\n상위 5개 하이퍼파라미터 조합:\")\n",
    "    print(top_5_params)\n",
    "    \n",
    "    # 하이퍼파라미터 검색 결과 저장\n",
    "    print(\"\\n하이퍼파라미터 검색 결과를 저장합니다...\")\n",
    "    with open(hp_search_results_path, 'wb') as f:\n",
    "        pickle.dump(step1_search, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28474b",
   "metadata": {},
   "source": [
    "### 최적 모델 미세 조정 및 성능 평가\n",
    "\n",
    "1단계를 바탕으로 학습률을 낮추고(0.01), 트리를 늘리고(10000), 조기 중단을 적용하여 최종 모델을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dfdd6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 최종 모델을 불러옵니다...\n",
      "최적 트리 개수: 2401\n",
      "최적 트리 개수: 2401\n"
     ]
    }
   ],
   "source": [
    "# 2단계: 최적 모델 미세 조정 - 낮은 학습률, 높은 n_estimators, early stopping\n",
    "\n",
    "# 최종 모델 파일 경로\n",
    "final_model_path = 'model_results/final_model.pkl'\n",
    "\n",
    "# 1단계에서 찾은 최적 하이퍼파라미터 가져오기\n",
    "best_params = step1_search.best_params_\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "X_test_brtfs = X_test[selected_features + onehot_columns].copy()\n",
    "\n",
    "# 검증용 데이터셋 분할 (원본 데이터에서 10%를 검증에 사용)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    X_train_brtfs, y_train_clean, test_size=0.1, random_state=42, stratify=y_train_clean\n",
    ")\n",
    "\n",
    "# 이미 학습된 최종 모델이 있는지 확인\n",
    "if os.path.exists(final_model_path):\n",
    "    print(\"저장된 최종 모델을 불러옵니다...\")\n",
    "    with open(final_model_path, 'rb') as f:\n",
    "        final_model = pickle.load(f)\n",
    "        # 저장된 평가 결과 불러오기\n",
    "    evals_result_path = 'model_results/evals_result.pkl'\n",
    "    if os.path.exists(evals_result_path):\n",
    "        with open(evals_result_path, 'rb') as f:\n",
    "            evals_result = pickle.load(f)\n",
    "    # 최적 트리 개수 확인 (XGBoost 버전에 따라 속성 이름이 다를 수 있음)\n",
    "    best_iteration = final_model.best_iteration if hasattr(final_model, 'best_iteration') else None\n",
    "    print(f\"최적 트리 개수: {best_iteration}\")\n",
    "else:\n",
    "    # ADASYN 적용 (최종 훈련 데이터에만)\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    X_train_final_resampled, y_train_final_resampled = adasyn.fit_resample(X_train_final, y_train_final)\n",
    "    \n",
    "    # 최종 모델 생성 - 낮은 학습률, 높은 n_estimators, early stopping 적용\n",
    "    final_model = XGBClassifier(\n",
    "        # 1단계에서 찾은 최적 하이퍼파라미터 적용\n",
    "        max_depth=int(best_params['classifier__max_depth']),\n",
    "        min_child_weight=best_params['classifier__min_child_weight'],\n",
    "        gamma=best_params['classifier__gamma'],\n",
    "        subsample=best_params['classifier__subsample'],\n",
    "        colsample_bytree=best_params['classifier__colsample_bytree'],\n",
    "        reg_alpha=best_params['classifier__reg_alpha'],\n",
    "        reg_lambda=best_params['classifier__reg_lambda'],\n",
    "        # 미세 조정을 위한 파라미터\n",
    "        learning_rate=0.01,           # 낮은 학습률\n",
    "        n_estimators=10000,           # 많은 트리 개수\n",
    "        early_stopping_rounds=200,    # 조기 중단\n",
    "        eval_metric='logloss',        # 평가 지표\n",
    "        random_state=42,\n",
    "        verbosity=1\n",
    "    )\n",
    "    \n",
    "    # 최종 모델 훈련 - 검증 데이터로 early stopping 모니터링\n",
    "    print(\"\\n2단계: 최적 모델 미세 조정 중...\")\n",
    "    final_model.fit(\n",
    "        X_train_final_resampled, y_train_final_resampled,\n",
    "        eval_set=[(X_train_final_resampled, y_train_final_resampled), \n",
    "                  (X_val_final, y_val_final)],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 학습 결과 및 모델 저장\n",
    "    with open(final_model_path, 'wb') as f:\n",
    "        pickle.dump(final_model, f)\n",
    "    \n",
    "    # 평가 결과 저장\n",
    "    evals_result = final_model.evals_result()\n",
    "    with open('model_results/evals_result.pkl', 'wb') as f:\n",
    "        pickle.dump(evals_result, f)\n",
    "\n",
    "# 최적 트리 개수 확인 (XGBoost 버전에 따라 속성 이름이 다를 수 있음)\n",
    "best_iteration = final_model.best_iteration if hasattr(final_model, 'best_iteration') else None\n",
    "print(f\"최적 트리 개수: {best_iteration}\")\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evals_result['validation_0']['logloss'], label='Training')\n",
    "plt.plot(evals_result['validation_1']['logloss'], label='Validation')\n",
    "plt.axvline(x=best_iteration, color='r', linestyle='--', label=f'Best iteration: {best_iteration}')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Training Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/learning_curve.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_best = final_model.predict(X_test_brtfs)\n",
    "y_proba_best = final_model.predict_proba(X_test_brtfs)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a2d95",
   "metadata": {},
   "source": [
    "### 최종 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cbf57ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<< 최종 XGBoost 모델 성능 >>\n",
      "F1 Score: 0.9354695016927006\n",
      "ROC AUC: 0.9081721627857662\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.48      0.63     23302\n",
      "           1       0.89      0.99      0.94     95507\n",
      "\n",
      "    accuracy                           0.89    118809\n",
      "   macro avg       0.90      0.74      0.78    118809\n",
      "weighted avg       0.89      0.89      0.88    118809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 지표 출력\n",
    "print(\"\\n<< 최종 XGBoost 모델 성능 >>\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_best))\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "643955ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(y_proba_best, bins=50, kde=True, color='skyblue')\n",
    "plt.title(\"Predict probability\")\n",
    "plt.xlabel(\"Probability of Class 1\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/prediction_probability.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09638109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_best), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Confusion Matrix (Best Model)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('plots/confusion_matrix.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f764ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr_best, tpr_best, _ = roc_curve(y_test, y_proba_best)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_best, tpr_best, label=f'Best Model ROC (AUC = {roc_auc_score(y_test, y_proba_best):.2f})', color='green')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Best Model ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/roc_curve.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a705ac",
   "metadata": {},
   "source": [
    "### 기본 변수 중요도 분석\n",
    "\n",
    "XGBoost의 기본 변수 중요도는 모델 전체에서 각 특성이 얼마나 자주 사용되었는지를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14504dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 20개 feature importance\n",
    "importances = final_model.feature_importances_\n",
    "features = X_test_brtfs.columns\n",
    "\n",
    "top_idx = importances.argsort()[::-1][:20]\n",
    "top_features = features[top_idx]\n",
    "top_importances = importances[top_idx]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=top_importances, y=top_features)\n",
    "plt.title(\"Top 20 Feature Importances (XGBoost)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/feature_importance.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7707ca3",
   "metadata": {},
   "source": [
    "### SHAP를 활용한 모델 해석\n",
    "\n",
    "**개별 예측에 대한 특성 기여도**를 파악하기 위한 **SHAP(SHapley Additive exPlanations)** 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a968ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\VSCodeProjects\\KAIST_MFE\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 기본 예측값 (base value): 0.030521773\n"
     ]
    }
   ],
   "source": [
    "# SHAP TreeExplainer 생성\n",
    "explainer = shap.TreeExplainer(final_model)\n",
    "\n",
    "# 훈련 데이터의 일부 샘플에 대한 SHAP 값 계산 (전체 데이터셋은 메모리 이슈가 있을 수 있음)\n",
    "X_train_sample = X_train_brtfs.sample(n=1000, random_state=42)\n",
    "shap_values = explainer.shap_values(X_train_sample)\n",
    "\n",
    "# 기대값 출력 (모델의 기본 예측값)\n",
    "print(\"모델의 기본 예측값 (base value):\", explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20e48ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부도 대출 사례 특성:\n",
      "loan_amnt       8075.0\n",
      "term                36\n",
      "int_rate         17.57\n",
      "installment      290.2\n",
      "sub_grade           16\n",
      "annual_inc     30000.0\n",
      "dti               23.2\n",
      "revol_bal       4103.0\n",
      "revol_util        80.5\n",
      "mort_acc           5.0\n",
      "Name: 96288, dtype: object\n",
      "\n",
      "정상 상환 대출 사례 특성:\n",
      "loan_amnt       6000.0\n",
      "term                36\n",
      "int_rate         16.29\n",
      "installment     211.81\n",
      "sub_grade           16\n",
      "annual_inc     40404.0\n",
      "dti              13.72\n",
      "revol_bal       4770.0\n",
      "revol_util        58.2\n",
      "mort_acc           0.0\n",
      "Name: 44427, dtype: object\n",
      "\n",
      "부도 사례 실제 클래스: 1\n",
      "정상 상환 사례 실제 클래스: 0\n",
      "\n",
      "부도 사례 예측 확률: 0.9998288\n",
      "정상 상환 사례 예측 확률: 0.00026364822\n"
     ]
    }
   ],
   "source": [
    "# 특정 샘플 예측에 대한 SHAP 값 분석\n",
    "# 부도 사례와 정상 상환 사례 각각 하나씩 선택\n",
    "loan_idx_default = X_train_sample.index[y_train[X_train_sample.index] == 1][0]  # 부도 사례\n",
    "loan_idx_paid = X_train_sample.index[y_train[X_train_sample.index] == 0][0]     # 정상 상환 사례\n",
    "\n",
    "# 선택된 대출 사례의 특성 값 출력\n",
    "print(\"부도 대출 사례 특성:\")\n",
    "print(X_train_brtfs.loc[loan_idx_default, :].head(10))\n",
    "print(\"\\n정상 상환 대출 사례 특성:\")\n",
    "print(X_train_brtfs.loc[loan_idx_paid, :].head(10))\n",
    "\n",
    "# 실제 클래스 확인\n",
    "print(\"\\n부도 사례 실제 클래스:\", y_train.loc[loan_idx_default])\n",
    "print(\"정상 상환 사례 실제 클래스:\", y_train.loc[loan_idx_paid])\n",
    "\n",
    "# 예측 확률 확인\n",
    "print(\"\\n부도 사례 예측 확률:\", final_model.predict_proba(X_train_brtfs.loc[loan_idx_default:loan_idx_default, :])[0][1])\n",
    "print(\"정상 상환 사례 예측 확률:\", final_model.predict_proba(X_train_brtfs.loc[loan_idx_paid:loan_idx_paid, :])[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c73c49",
   "metadata": {},
   "source": [
    "아래의 SHAP Force Plot은 개별 대출 사례에 대한 모델의 예측을 설명합니다:\n",
    "\n",
    "- **빨간색** 특성은 부도 확률을 **증가**시키는 요인\n",
    "- **파란색** 특성은 부도 확률을 **감소**시키는 요인\n",
    "- 각 특성의 **너비**는 그 영향력의 **크기**를 나타냄\n",
    "- **base value**는 데이터셋 전체의 평균 예측값\n",
    "- **output value**는 해당 사례의 최종 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d8ad69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:9: UserWarning: Glyph 48512 (\\N{HANGUL SYLLABLE BU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:9: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:9: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:9: UserWarning: Glyph 47168 (\\N{HANGUL SYLLABLE RYE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:10: UserWarning: Glyph 48512 (\\N{HANGUL SYLLABLE BU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_default.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:10: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_default.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:10: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_default.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:10: UserWarning: Glyph 47168 (\\N{HANGUL SYLLABLE RYE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_default.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:21: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:21: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:21: UserWarning: Glyph 54872 (\\N{HANGUL SYLLABLE HWAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:21: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:21: UserWarning: Glyph 47168 (\\N{HANGUL SYLLABLE RYE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:22: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_paid.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:22: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_paid.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:22: UserWarning: Glyph 54872 (\\N{HANGUL SYLLABLE HWAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_paid.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:22: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_paid.png', bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\2663991226.py:22: UserWarning: Glyph 47168 (\\N{HANGUL SYLLABLE RYE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('plots/shap_force_plot_paid.png', bbox_inches='tight', dpi=300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SHAP Force Plot - 부도 사례\n",
    "plt.figure(figsize=(16, 5))\n",
    "shap_idx_default = np.where(np.array(X_train_sample.index) == loan_idx_default)[0][0]\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values[shap_idx_default, :],\n",
    "                X_train_sample.iloc[shap_idx_default, :],\n",
    "                matplotlib=True, show=False)\n",
    "plt.title(\"SHAP Force Plot - 부도 사례\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/shap_force_plot_default.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# SHAP Force Plot - 정상 상환 사례\n",
    "plt.figure(figsize=(16, 5))\n",
    "shap_idx_paid = np.where(np.array(X_train_sample.index) == loan_idx_paid)[0][0]\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values[shap_idx_paid, :],\n",
    "                X_train_sample.iloc[shap_idx_paid, :],\n",
    "                matplotlib=True, show=False)\n",
    "plt.title(\"SHAP Force Plot - 정상 상환 사례\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/shap_force_plot_paid.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66032b",
   "metadata": {},
   "source": [
    "### SHAP 글로벌 분석 - 전체 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be27eb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\870761578.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train_sample, plot_type=\"bar\", show=False)\n"
     ]
    }
   ],
   "source": [
    "# SHAP Summary Plot - 모든 특성의 영향력 시각화\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_train_sample, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/shap_feature_importance.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "470b7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_26632\\4017402232.py:3: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train_sample, show=False)\n"
     ]
    }
   ],
   "source": [
    "# SHAP Summary Plot - 각 특성값에 따른 영향력 변화 시각화\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_train_sample, show=False)\n",
    "plt.title(\"SHAP Summary Plot\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/shap_summary_plot.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75d7a8",
   "metadata": {},
   "source": [
    "SHAP 요약 플롯의 해석:\n",
    "\n",
    "1. **Feature Importance**:\n",
    "   - 막대 그래프는 각 특성의 평균 절대 SHAP 값 기준 중요도를 보여줍니다.\n",
    "   - XGBoost의 기본 feature_importance와 달리 각 예측에 대한 기여도의 평균입니다.\n",
    "\n",
    "2. **Summary Plot**:\n",
    "   - 각 점은 하나의 샘플에 대한 하나의 특성 값을 나타냅니다.\n",
    "   - 색상: 특성 값이 **높을수록 빨간색**, **낮을수록 파란색**\n",
    "   - 수평 위치: SHAP 값으로, **오른쪽**은 부도 확률을 **증가**시키고, **왼쪽**은 **감소**시킴\n",
    "   - 이를 통해 특성 값의 변화에 따른 모델 예측 영향을 파악할 수 있습니다.\n",
    "\n",
    "예를 들어, 일부 특성들은 값이 증가할수록 부도 확률이 높아지는 반면(빨간 점이 오른쪽에 위치), \n",
    "다른 특성들은 값이 낮을수록 부도 확률이 높아집니다(파란 점이 오른쪽에 위치)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_best)\n",
    "avg_precision = average_precision_score(y_test, y_proba_best)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/precision_recall_curve.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd4e1b",
   "metadata": {},
   "source": [
    "## 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece7cd4",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "source": [
    "본 분석에서는 XGBoost 알고리즘을 사용하여 은행 대출의 부도 여부를 예측하는 모델을 구축했습니다. 주요 결론은 다음과 같습니다:\n",
    "\n",
    "1. **데이터 전처리**: 결측치 처리, 이상치 제거, Boruta 알고리즘을 통한 변수 선택을 수행하여 모델의 기반을 마련했습니다.\n",
    "\n",
    "2. **클래스 불균형 처리**: 계층적 샘플링으로 훈련/테스트 세트의 클래스 분포를 유지하고, ADASYN 알고리즘을 교차 검증 내에서 올바르게 적용하여 소수 클래스에 대한 예측 성능을 개선했습니다.\n",
    "\n",
    "3. **이단계 최적화 접근법**: \n",
    "   - 초기 하이퍼파라미터 탐색 단계에서는 고정된 n_estimators로 공정한 비교를 수행\n",
    "   - 최종 모델 구축 단계에서는 낮은 학습률과 early stopping을 적용하여 최적의 트리 개수를 찾음\n",
    "\n",
    "4. **모델 해석**: \n",
    "   - XGBoost 변수 중요도를 통해 주요 특성들을 식별\n",
    "   - SHAP 분석을 통해 개별 대출 사례에 대한 예측 근거를 파악하고, 특성값 변화에 따른 예측 영향을 이해\n",
    "\n",
    "5. **성능 평가**: F1 점수, ROC-AUC, 정밀도-재현율 곡선 등 다양한 지표를 통해 모델의 성능을 종합적으로 평가했습니다.\n",
    "\n",
    "이러한 접근법은 단순히 높은 예측 정확도를 달성하는 것을 넘어, 모델의 예측 결정을 이해하고 설명할 수 있는 프레임워크를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05226a9f",
   "metadata": {},
   "source": [
    "## Appendix : 여러 Gradiant boosting 모델의 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 : Catboost\n",
    "\n",
    "params = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'iterations': [200, 500, 1000],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "cat = CatBoostClassifier(verbose=1)\n",
    "random_search = RandomizedSearchCV(cat, param_distributions=params, cv=3, scoring='f1', n_iter=10)\n",
    "# ➕ early stopping 적용 (fit_params에 전달)\n",
    "random_search.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    eval_set=(X_test_brtfs, y_test),              # 검증 데이터\n",
    "    early_stopping_rounds=50,                     # 조기 종료 조건\n",
    "    use_best_model=True                           # 최고 모델 사용\n",
    ")\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# 예측\n",
    "y_pred_best = best_model.predict(X_test_brtfs)\n",
    "y_proba_best = best_model.predict_proba(X_test_brtfs)[:, 1]\n",
    "\n",
    "# 평가 지표 출력\n",
    "print(\"<< Best Catboost model perfomance >>\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_best))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 : LightGBM\n",
    "\n",
    "# 1. 하이퍼파라미터 후보 설정\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 300, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10, -1],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'min_child_samples': [10, 20, 30, 50],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# 2. 모델 정의\n",
    "lgb = LGBMClassifier(random_state=42)\n",
    "\n",
    "# 3. RandomizedSearchCV 정의\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,                   # 탐색 횟수\n",
    "    scoring='f1',                # 평가 지표 (불균형이라면 f1 추천)\n",
    "    cv=3,                        # 교차 검증 폴드 수\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1                    # 병렬 처리\n",
    ")\n",
    "\n",
    "# 4. 학습 (X_train_resampled은 오버샘플링된 학습 데이터)\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 5. 최고 성능 모델 사용\n",
    "best_lgb = random_search.best_estimator_\n",
    "print(\"Best parameters found:\\n\", random_search.best_params_)\n",
    "\n",
    "# 6. 예측 및 평가\n",
    "y_pred = best_lgb.predict(X_test_brtfs)\n",
    "y_proba = best_lgb.predict_proba(X_test_brtfs)[:, 1]\n",
    "\n",
    "# 평가 지표 출력\n",
    "print(\"<< Light GBM perfomance >>\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dab0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 : Soft voting\n",
    "\n",
    "# 예측 확률 가져오기\n",
    "cat_proba = best_model.predict_proba(X_test_brtfs)[:, 1]\n",
    "lgb_proba = best_lgb.predict_proba(X_test_brtfs)[:, 1]\n",
    "\n",
    "# Soft voting (평균 확률)\n",
    "ensemble_proba = (cat_proba + lgb_proba) / 2\n",
    "\n",
    "# 최종 예측 (0.5 기준)\n",
    "ensemble_pred = (ensemble_proba >= 0.5).astype(int)\n",
    "\n",
    "# 성능 평가\n",
    "print(\"<< Soft voting model perfomance >>\")\n",
    "print(\"F1 Score:\", f1_score(y_test, ensemble_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, ensemble_proba))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 : Stacking with Logistic regression\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# stacking 모델 정의 (메타 모델: 로지스틱 회귀)\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('cat', best_model),\n",
    "        ('lgb', best_lgb)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),  # 메타 모델\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=False  # True로 하면 원래 feature도 같이 메타 모델에 전달\n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = stacking_model.predict(X_test_brtfs)\n",
    "y_proba = stacking_model.predict_proba(X_test_brtfs)[:, 1]\n",
    "\n",
    "print(\"<< Stacking model perfomance >>\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

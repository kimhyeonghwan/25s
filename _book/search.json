[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KAIST MFE, 2025 Spring",
    "section": "",
    "text": "Welcome!\n안녕하세요, KAIST MFE 25년 봄학기에 이수한 과목의 과제 등을 정리해두었습니다.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "빅데이터1.html",
    "href": "빅데이터1.html",
    "title": "1  빅데이터와 금융자료 분석 CH1",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n\n\nmissdict = {'f1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n            'f2': [10., None, 20., 30., None, 50., 60., 70., 80., 90.],\n            'f3': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C']}\nmissdata = pd.DataFrame( missdict )\nmissdata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   f1      10 non-null     int64  \n 1   f2      8 non-null      float64\n 2   f3      10 non-null     object \ndtypes: float64(1), int64(1), object(1)\nmemory usage: 368.0+ bytes\n\n\n\nmissdata.isna().mean()\n\nf1    0.0\nf2    0.2\nf3    0.0\ndtype: float64\n\n\n\ntmpdata1 = missdata.dropna()\ntmpdata1\n\n\n\n\n\n\n\n\n\nf1\nf2\nf3\n\n\n\n\n0\n1\n10.0\nA\n\n\n2\n3\n20.0\nA\n\n\n3\n4\n30.0\nA\n\n\n5\n6\n50.0\nB\n\n\n6\n7\n60.0\nB\n\n\n7\n8\n70.0\nB\n\n\n8\n9\n80.0\nC\n\n\n9\n10\n90.0\nC\n\n\n\n\n\n\n\n\n\ntmpdata2 = missdata.dropna( subset=['f3'] )\ntmpdata2\n\n\n\n\n\n\n\n\n\nf1\nf2\nf3\n\n\n\n\n0\n1\n10.0\nA\n\n\n1\n2\nNaN\nA\n\n\n2\n3\n20.0\nA\n\n\n3\n4\n30.0\nA\n\n\n4\n5\nNaN\nB\n\n\n5\n6\n50.0\nB\n\n\n6\n7\n60.0\nB\n\n\n7\n8\n70.0\nB\n\n\n8\n9\n80.0\nC\n\n\n9\n10\n90.0\nC\n\n\n\n\n\n\n\n\n\nnumdata = missdata.select_dtypes(include=['int64', 'float64'])\ntmpdata3 = numdata.fillna( -999, inplace=False )\ntmpdata3.describe()\n\n\n\n\n\n\n\n\n\nf1\nf2\n\n\n\n\ncount\n10.00000\n10.000000\n\n\nmean\n5.50000\n-158.800000\n\n\nstd\n3.02765\n443.562297\n\n\nmin\n1.00000\n-999.000000\n\n\n25%\n3.25000\n12.500000\n\n\n50%\n5.50000\n40.000000\n\n\n75%\n7.75000\n67.500000\n\n\nmax\n10.00000\n90.000000\n\n\n\n\n\n\n\n\n\nnumdata.mean()\n\nf1     5.50\nf2    51.25\ndtype: float64\n\n\n\ntmpdata4 = numdata.fillna( numdata.mean(), inplace=False )\ntmpdata4\n\n\n\n\n\n\n\n\n\nf1\nf2\n\n\n\n\n0\n1\n10.00\n\n\n1\n2\n51.25\n\n\n2\n3\n20.00\n\n\n3\n4\n30.00\n\n\n4\n5\n51.25\n\n\n5\n6\n50.00\n\n\n6\n7\n60.00\n\n\n7\n8\n70.00\n\n\n8\n9\n80.00\n\n\n9\n10\n90.00\n\n\n\n\n\n\n\n\n\nmissdata.groupby('f3')['f2'].mean()\n\nf3\nA    20.0\nB    60.0\nC    85.0\nName: f2, dtype: float64\n\n\n\nmissdata.groupby('f3')['f2'].transform('mean')\n\n0    20.0\n1    20.0\n2    20.0\n3    20.0\n4    60.0\n5    60.0\n6    60.0\n7    60.0\n8    85.0\n9    85.0\nName: f2, dtype: float64\n\n\n\ntmpdata5 = numdata.copy()\ntmpdata5['f2'].fillna( missdata.groupby('f3')['f2'].transform('mean'), inplace=True)\ntmpdata5\n\n/var/folders/n2/jbh_0_091bx8qgz7j87t2qwc0000gp/T/ipykernel_25894/622840210.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  tmpdata5['f2'].fillna( missdata.groupby('f3')['f2'].transform('mean'),inplace=True)\n\n\n\n\n\n\n\n\n\n\nf1\nf2\n\n\n\n\n0\n1\n10.0\n\n\n1\n2\n20.0\n\n\n2\n3\n20.0\n\n\n3\n4\n30.0\n\n\n4\n5\n60.0\n\n\n5\n6\n50.0\n\n\n6\n7\n60.0\n\n\n7\n8\n70.0\n\n\n8\n9\n80.0\n\n\n9\n10\n90.0\n\n\n\n\n\n\n\n\n\nmissdata_tr = missdata.dropna()\nx_tr = missdata_tr[['f1']]\ny_tr = missdata_tr['f2']\n\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit( x_tr, y_tr )\n\nmissdata_ts = missdata [ missdata.isnull().any(axis=1) ]\nx_ts = missdata_ts[['f1']]\n\npredicted_values = model.predict( x_ts )\ntmpdata6 = missdata.copy()\ntmpdata6.loc[ tmpdata6['f2'].isnull(), 'f2'] = predicted_values\ntmpdata6\n\n\n\n\n\n\n\n\n\nf1\nf2\nf3\n\n\n\n\n0\n1\n10.000000\nA\n\n\n1\n2\n14.191176\nA\n\n\n2\n3\n20.000000\nA\n\n\n3\n4\n30.000000\nA\n\n\n4\n5\n41.985294\nB\n\n\n5\n6\n50.000000\nB\n\n\n6\n7\n60.000000\nB\n\n\n7\n8\n70.000000\nB\n\n\n8\n9\n80.000000\nC\n\n\n9\n10\n90.000000\nC\n\n\n\n\n\n\n\n\n\nmissdata_num = missdata.copy()\nmissdata_num['f3']=missdata_num['f3'].map({'A':1,'B':2,'C':3})\n\n\nmissdata_num\n\n\n\n\n\n\n\n\n\nf1\nf2\nf3\n\n\n\n\n0\n1\n10.0\n1\n\n\n1\n2\nNaN\n1\n\n\n2\n3\n20.0\n1\n\n\n3\n4\n30.0\n1\n\n\n4\n5\nNaN\n2\n\n\n5\n6\n50.0\n2\n\n\n6\n7\n60.0\n2\n\n\n7\n8\n70.0\n2\n\n\n8\n9\n80.0\n3\n\n\n9\n10\n90.0\n3\n\n\n\n\n\n\n\n\n\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=2)\ntmpdata7 = imputer.fit_transform(missdata_num)\n\n\npd.DataFrame( tmpdata7 )\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n1.0\n10.0\n1.0\n\n\n1\n2.0\n15.0\n1.0\n\n\n2\n3.0\n20.0\n1.0\n\n\n3\n4.0\n30.0\n1.0\n\n\n4\n5.0\n40.0\n2.0\n\n\n5\n6.0\n50.0\n2.0\n\n\n6\n7.0\n60.0\n2.0\n\n\n7\n8.0\n70.0\n2.0\n\n\n8\n9.0\n80.0\n3.0\n\n\n9\n10.0\n90.0\n3.0\n\n\n\n\n\n\n\n\n\noutdict = {'A': [10, 0.02, 0.3, 40, 50, 60, 712, 80, 90, 1003],\n           'B': [0.05, 0.00015, 25, 35, 45, 205, 65, 75, 85, 3905]}\noutdata = pd.DataFrame( outdict )\n\nQ1 = outdata.quantile(0.25)\nQ3 = outdata.quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n((outdata &lt; lower_bound) | (outdata &gt; upper_bound))\n\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\nFalse\nFalse\n\n\n1\nFalse\nFalse\n\n\n2\nFalse\nFalse\n\n\n3\nFalse\nFalse\n\n\n4\nFalse\nFalse\n\n\n5\nFalse\nTrue\n\n\n6\nTrue\nFalse\n\n\n7\nFalse\nFalse\n\n\n8\nFalse\nFalse\n\n\n9\nTrue\nTrue\n\n\n\n\n\n\n\n\n\noutliers = ((outdata &lt; lower_bound) | (outdata &gt; upper_bound)).any(axis=1)\noutliersdata = outdata[ outliers ]\noutliersdata\n\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n5\n60.0\n205.0\n\n\n6\n712.0\n65.0\n\n\n9\n1003.0\n3905.0\n\n\n\n\n\n\n\n\n\nstandardizeddata = (outdata - outdata.mean()) / outdata.std()\nstandardizeddata\n\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\n-0.552206\n-0.364647\n\n\n1\n-0.580536\n-0.364688\n\n\n2\n-0.579741\n-0.344154\n\n\n3\n-0.467047\n-0.335940\n\n\n4\n-0.438661\n-0.327727\n\n\n5\n-0.410274\n-0.196309\n\n\n6\n1.440519\n-0.311300\n\n\n7\n-0.353501\n-0.303086\n\n\n8\n-0.325115\n-0.294872\n\n\n9\n2.266563\n2.842723\n\n\n\n\n\n\n\n\n\noutliers2 = ((standardizeddata &lt; -3) | (standardizeddata &gt; 3)).any(axis=1)\noutliersdata2 = outdata[ outliers2 ]\noutliersdata2\n\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nnp.random.seed(42)\nX_inliers = 0.3 * np.random.randn(100, 2)\nX_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\nX = np.r_[X_inliers + 2, X_inliers - 2, X_outliers]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(X[:, 0], X[:, 1], color='k', s=20)\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import LocalOutlierFactor\nclf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\ny_pred = clf.fit_predict(X) # 1: inlier, -1: outlier\noutlier_mask = y_pred == -1\n\nplt.figure(figsize=(5, 4))\nplt.scatter(X[:, 0], X[:, 1], color='b', s=20, label='Inliers')\nplt.scatter(X[outlier_mask, 0], X[outlier_mask, 1], color='r', s=50,label='Outliers')\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nfrom sklearn.ensemble import IsolationForest\nclf2 = IsolationForest(contamination=0.1)\n# contamination : 이상치 비율\n# n_estimators : 나무의 갯수 (defalut 100)\n# max_features : 각 나무별 특성변수의 갯수(default 1)\nclf2.fit( X )\ny_pred2 = clf2.predict( X ) # 1: inlier, -1: outlier\noutlier_mask2 = y_pred2 == -1\n\nplt.figure(figsize=(5, 4))\nplt.scatter(X[:, 0], X[:, 1], color='b', s=20, label='Inliers')\nplt.scatter(X[outlier_mask2, 0], X[outlier_mask2, 1], color='r', s=50,label='Outliers')\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nclf2.score_samples(X)\n\narray([-0.39567479, -0.43973362, -0.38576701, -0.4625295 , -0.39169087,\n       -0.39353101, -0.44632054, -0.4539587 , -0.39410011, -0.42823486,\n       -0.43802322, -0.4231585 , -0.38600184, -0.40324911, -0.38778406,\n       -0.46849881, -0.4075734 , -0.43420431, -0.45140279, -0.4113938 ,\n       -0.40036102, -0.38335266, -0.42666089, -0.41104579, -0.44476313,\n       -0.38744281, -0.39942914, -0.44257912, -0.38938554, -0.40470075,\n       -0.39006555, -0.42881353, -0.44275864, -0.40154039, -0.39729665,\n       -0.42434279, -0.42743206, -0.57699503, -0.38628797, -0.45454533,\n       -0.3864026 , -0.44513991, -0.39598029, -0.41231495, -0.39270763,\n       -0.40568073, -0.39005843, -0.43210962, -0.38601781, -0.38485125,\n       -0.41991455, -0.40181793, -0.38788591, -0.48400217, -0.38538727,\n       -0.47693547, -0.50815903, -0.39115267, -0.40423505, -0.43216634,\n       -0.4254748 , -0.48475901, -0.4890737 , -0.40357175, -0.39439224,\n       -0.42406868, -0.40171635, -0.44870204, -0.38761922, -0.43170548,\n       -0.42364173, -0.43593615, -0.39560581, -0.4391784 , -0.39543452,\n       -0.38550106, -0.38910014, -0.39558501, -0.48693408, -0.41865632,\n       -0.40964165, -0.43730378, -0.41716448, -0.47893783, -0.39791987,\n       -0.40492088, -0.38431516, -0.39544321, -0.42208103, -0.53522817,\n       -0.41839783, -0.40171635, -0.39362168, -0.39333773, -0.44128807,\n       -0.40208128, -0.40907841, -0.39096216, -0.38929625, -0.40645206,\n       -0.38953796, -0.43147334, -0.38691831, -0.45292849, -0.39365031,\n       -0.40064735, -0.46513506, -0.48209563, -0.39635657, -0.44569517,\n       -0.4496465 , -0.43243444, -0.39406682, -0.40625773, -0.39826724,\n       -0.46462545, -0.40782229, -0.42572527, -0.46599338, -0.42852596,\n       -0.40082304, -0.38971614, -0.4628486 , -0.4219109 , -0.46365237,\n       -0.39237271, -0.40320941, -0.42432754, -0.40309339, -0.40204058,\n       -0.39044555, -0.43501511, -0.4324525 , -0.40503508, -0.40259674,\n       -0.42956023, -0.42799201, -0.56257644, -0.38875652, -0.47585014,\n       -0.3835507 , -0.4556408 , -0.406217  , -0.40385118, -0.39458774,\n       -0.40122018, -0.40401747, -0.4443972 , -0.38320086, -0.3834212 ,\n       -0.44945534, -0.4060406 , -0.38476589, -0.46817324, -0.38466101,\n       -0.47610349, -0.49275615, -0.38344594, -0.40974845, -0.42395885,\n       -0.42189161, -0.49261883, -0.48518689, -0.40901991, -0.39452123,\n       -0.44785724, -0.40375287, -0.45749968, -0.40496115, -0.4260838 ,\n       -0.41810669, -0.44560803, -0.38806155, -0.45523273, -0.38817405,\n       -0.38177641, -0.39724261, -0.40279204, -0.46677259, -0.42162856,\n       -0.4086809 , -0.43961327, -0.40404401, -0.45862325, -0.40473907,\n       -0.41509113, -0.38081908, -0.39036169, -0.42441162, -0.52130968,\n       -0.41557892, -0.40347146, -0.39318444, -0.38921027, -0.46342999,\n       -0.39756969, -0.41357841, -0.38429305, -0.40297782, -0.40881293,\n       -0.60259641, -0.44411547, -0.57052254, -0.50247903, -0.73212838,\n       -0.64786135, -0.55623141, -0.45375541, -0.68754218, -0.67833274,\n       -0.70698798, -0.63422967, -0.64031155, -0.78183101, -0.65477657,\n       -0.67178443, -0.67084008, -0.68580391, -0.71446705, -0.64861428])",
    "crumbs": [
      "머신러닝2('25 봄)",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>빅데이터와 금융자료 분석 CH1</span>"
    ]
  },
  {
    "objectID": "빅데이터_과제.html",
    "href": "빅데이터_과제.html",
    "title": "2  빅데이터와 금융자료 분석 기말대체과제",
    "section": "",
    "text": "2.1 Question 1",
    "crumbs": [
      "머신러닝2('25 봄)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>빅데이터와 금융자료 분석 기말대체과제</span>"
    ]
  },
  {
    "objectID": "빅데이터_과제.html#question-1",
    "href": "빅데이터_과제.html#question-1",
    "title": "2  빅데이터와 금융자료 분석 기말대체과제",
    "section": "",
    "text": "2.1.1 (1)\n주어진 자료 중 범주형 변수 각각에 대해 적절한 전처리를 선택하고 진행하여라.\n\nimport numpy as np\nimport pandas as pd\n\nbank = pd.read_csv('data/prob1_bank.csv')\nbank.info() # 전체 11개 칼럼에 null값은 없으며, 범주형 9개 및 숫자형 2개\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4521 entries, 0 to 4520\nData columns (total 11 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   age        4521 non-null   int64 \n 1   job        4521 non-null   object\n 2   marital    4521 non-null   object\n 3   education  4521 non-null   object\n 4   default    4521 non-null   object\n 5   balance    4521 non-null   int64 \n 6   housing    4521 non-null   object\n 7   loan       4521 non-null   object\n 8   contact    4521 non-null   object\n 9   month      4521 non-null   object\n 10  y          4521 non-null   object\ndtypes: int64(2), object(9)\nmemory usage: 388.6+ KB\n\n\n\nbank.select_dtypes(include='object').nunique()\n# 범주형 9개 중, 목적변수를 포함하여 4개는 '여부'에 대한 이진변수이며 나머지는 3~12개의 고유값\n\njob          12\nmarital       3\neducation     4\ndefault       2\nhousing       2\nloan          2\ncontact       3\nmonth        12\ny             2\ndtype: int64\n\n\n\nbank['job'].value_counts()\n# 직업의 경우, 12개의 범주로 구성됨. 특별히 한 값에 치중되는 모습도 보이지 않고,\n# 순서가 없으므로 원-핫 인코딩으로 처리 예정\n\njob\nmanagement       969\nblue-collar      946\ntechnician       768\nadmin.           478\nservices         417\nretired          230\nself-employed    183\nentrepreneur     168\nunemployed       128\nhousemaid        112\nstudent           84\nunknown           38\nName: count, dtype: int64\n\n\n\nbank['marital'].value_counts()\n# 결혼 여부는 싱글/결혼/이혼 3진변수임. 순서가 없으므로 원-핫 인코딩으로 처리 예정\n\nmarital\nmarried     2797\nsingle      1196\ndivorced     528\nName: count, dtype: int64\n\n\n\nbank['education'].value_counts()\n# 학력에 대한 내용은 primary - secondary - tertiary 순이므로 1~3 라벨인코딩 처리 예정\n# unknown은 학력수준이 낮을 가능성이 높을 것으로 추정, 0으로 처리하여 하나의 응답값으로 간주함.\n\neducation\nsecondary    2306\ntertiary     1350\nprimary       678\nunknown       187\nName: count, dtype: int64\n\n\n\nbank['contact'].value_counts()\n# 연락방법에 대한 내용은 telephone - cellular 순으로 연락이 편리하므로 1~2 라벨인코딩 처리 예정\n# unknown은 연락 편의성이 가장 떨어질 것으로 보임. 0으로 처리하여 라벨인코딩 처리 예정\n\ncontact\ncellular     2896\nunknown      1324\ntelephone     301\nName: count, dtype: int64\n\n\n\nbank['month'].value_counts()\n# 달에 대한 내용으로, 1~12개월 순서에 따른 라벨인코딩 처리 예정\n\nmonth\nmay    1398\njul     706\naug     633\njun     531\nnov     389\napr     293\nfeb     222\njan     148\noct      80\nsep      52\nmar      49\ndec      20\nName: count, dtype: int64\n\n\n\n# 범주형 변수 처리\n\n# 1. job, marital -&gt; One-Hot Encoding\nbank = pd.get_dummies(bank, columns=['job', 'marital'], drop_first=True)\n\n# 2. education, contact, month &gt; Label Encoding\nedu_map = {'unknown': 0,'primary': 1,'secondary': 2,'tertiary': 3}\nbank['education'] = bank['education'].map(edu_map)\n\ncontact_map = {'unknown': 0,'telephone': 1,'cellular': 2}\nbank['contact'] = bank['contact'].map(contact_map)\n\nmonth_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n               'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\nmonth_map = {month: i for i, month in enumerate(month_order)}\nbank['month'] = bank['month'].map(month_map)\n\n# 3. default, housing, loan, y &gt; Label Encoding (binary, yes=1 / no=0)\nbinary_cols = ['default', 'housing', 'loan', 'y']\nfor col in binary_cols: bank[col] = bank[col].map({'yes': 1, 'no': 0})\n\nprint(bank.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4521 entries, 0 to 4520\nData columns (total 22 columns):\n #   Column             Non-Null Count  Dtype\n---  ------             --------------  -----\n 0   age                4521 non-null   int64\n 1   education          4521 non-null   int64\n 2   default            4521 non-null   int64\n 3   balance            4521 non-null   int64\n 4   housing            4521 non-null   int64\n 5   loan               4521 non-null   int64\n 6   contact            4521 non-null   int64\n 7   month              4521 non-null   int64\n 8   y                  4521 non-null   int64\n 9   job_blue-collar    4521 non-null   bool \n 10  job_entrepreneur   4521 non-null   bool \n 11  job_housemaid      4521 non-null   bool \n 12  job_management     4521 non-null   bool \n 13  job_retired        4521 non-null   bool \n 14  job_self-employed  4521 non-null   bool \n 15  job_services       4521 non-null   bool \n 16  job_student        4521 non-null   bool \n 17  job_technician     4521 non-null   bool \n 18  job_unemployed     4521 non-null   bool \n 19  job_unknown        4521 non-null   bool \n 20  marital_married    4521 non-null   bool \n 21  marital_single     4521 non-null   bool \ndtypes: bool(13), int64(9)\nmemory usage: 375.4 KB\nNone\n\n\n\n\n2.1.2 (2)\n주어진 자료 중 수치형 변수 각각에 대해 적절한 전처리를 선택하고 진행하여라.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1. age 분포\nplt.figure(figsize=(10, 4))\nsns.histplot(bank['age'], bins=30, kde=True)\nplt.title(\"Distribution of Age\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.tight_layout()\nplt.show()\n\n# 2. balance 분포\nplt.figure(figsize=(10, 4))\nsns.histplot(bank['balance'], bins=30, kde=True)\nplt.title(\"Distribution of Balance\")\nplt.xlabel(\"Balance\")\nplt.ylabel(\"Count\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbank['age'].describe()\n# age는 오른쪽 skew가 미세하게 있는 정규분포와 가까운 형태. 표준화만 진행\n\ncount    4521.000000\nmean       41.170095\nstd        10.576211\nmin        19.000000\n25%        33.000000\n50%        39.000000\n75%        49.000000\nmax        87.000000\nName: age, dtype: float64\n\n\n\nbank['balance'].describe()\n# balance는 음수도 존재하고, 값이 매우 극단적으로 치우쳐져 있는 형태. log변환 및 표준화 진행\n# 이후 LOF 방식으로 두 수치형변수에 대한 이상치 탐지, 약 1% 수준의 이상치 제거 예정\n\ncount     4521.000000\nmean      1422.657819\nstd       3009.638142\nmin      -3313.000000\n25%         69.000000\n50%        444.000000\n75%       1480.000000\nmax      71188.000000\nName: balance, dtype: float64\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import LocalOutlierFactor\nimport numpy as np\n\n# 1. balance 로그변환 (음수 대비)\nmin_bal = bank['balance'].min()\nbank['log_balance'] = np.log1p(bank['balance'] - min_bal + 1)\n\n# 2. balance + age 표준화\nscaler = StandardScaler()\nbank[['std_log_balance', 'std_age']] = scaler.fit_transform(bank[['log_balance', 'age']])\n\n# 3. LOF 이상치 탐지 (다변량: log_balance + age)\n# 적절한 파라미터 조정으로 balance의 최소, 최대값을 효과적으로 제거\nX_scaled = bank[['std_log_balance', 'std_age']]\nlof = LocalOutlierFactor(n_neighbors=30, contamination=0.01)\nbank['is_outlier'] = (lof.fit_predict(X_scaled) == -1).astype(int)\n\n# 4. 이상치 시각화 (scatter plot)\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=bank, x='std_log_balance', y='std_age',\n                hue='is_outlier', palette='Set1', alpha=0.7)\nplt.title(\"Scatter Plot of Standardized Log Balance vs. Age\\n(LOF Outlier Detection)\")\nplt.xlabel(\"Standardized Log Balance\")\nplt.ylabel(\"Standardized Age\")\nplt.legend(title=\"Outlier\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 이상치 1%가 제거된 것을 확인할 수 있음\nbank_clean = bank[bank['is_outlier'] == 0].copy()\nbank_clean\n\n\n\n\n\n\n\n\n\nage\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nmonth\ny\njob_blue-collar\n...\njob_student\njob_technician\njob_unemployed\njob_unknown\nmarital_married\nmarital_single\nlog_balance\nstd_log_balance\nstd_age\nis_outlier\n\n\n\n\n0\n30\n1\n0\n1787\n0\n0\n2\n9\n0\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\n8.537388\n0.431049\n-1.056270\n0\n\n\n1\n33\n2\n0\n4789\n1\n1\n2\n4\n0\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n9.000113\n1.608188\n-0.772583\n0\n\n\n2\n35\n3\n0\n1350\n1\n0\n2\n3\n0\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n8.447843\n0.203253\n-0.583458\n0\n\n\n3\n30\n3\n0\n1476\n1\n1\n0\n5\n0\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n8.474494\n0.271052\n-1.056270\n0\n\n\n4\n59\n2\n0\n0\n1\n0\n0\n4\n0\nTrue\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n8.106213\n-0.665829\n1.686036\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4515\n32\n2\n0\n473\n1\n0\n2\n6\n0\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n8.239593\n-0.326519\n-0.867145\n0\n\n\n4516\n33\n2\n0\n-333\n1\n0\n2\n6\n0\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n8.000349\n-0.935138\n-0.772583\n0\n\n\n4518\n57\n2\n0\n295\n0\n0\n2\n7\n0\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n8.191463\n-0.448959\n1.496912\n0\n\n\n4519\n28\n2\n0\n1137\n0\n0\n2\n1\n0\nTrue\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n8.401109\n0.084364\n-1.245394\n0\n\n\n4520\n44\n3\n0\n1136\n1\n1\n2\n3\n0\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n8.400884\n0.083793\n0.267602\n0\n\n\n\n\n4475 rows × 26 columns\n\n\n\n\n\n\n2.1.3 (3)\n주어진 자료에 클래스 불균형이 있는지 확인한 뒤, 이에 대한 적절한 전처리 방법을 선택하여 진행하여라.\n\n# 약 9:1로 0(No)의 비율이 압도적으로 많음. 클래스불균형 존재\n\nclass_counts = bank_clean['y'].value_counts(normalize=True)\nplt.figure(figsize=(6, 4))\nsns.barplot(x=class_counts.index, y=class_counts.values, legend=False)\nplt.title(\"Class Imbalance\")\nplt.xlabel(\"y\")\nplt.ylim(0, 1)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 수치형 변수의 scatter plot상으로 특정 수치형 변수에 따른 치우침은 관측되지 않음.\n\nX = bank_clean[['std_log_balance','std_age']]\ny = bank_clean['y']\nplt.figure(figsize=(10, 6))\nplt.plot(X.loc[y == 0, 'std_log_balance'], X.loc[y == 0, 'std_age'], 'b+', label=\"class 0\")\nplt.plot(X.loc[y == 1, 'std_log_balance'], X.loc[y == 1, 'std_age'], 'r*', label=\"class 1\")\nplt.legend()\nplt.xlabel(\"std_log_balance\")\nplt.ylabel(\"std_age\")\nplt.title(\"Scatter Plot by Class (y)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# 표본의 수가 적은 편이므로 oversampling 진행\n# 데이터의 구조가 그다지 복잡하지 않아 SMOTE 알고리즘을 적용하여 처리\nfrom imblearn.over_sampling import SMOTE\n\noversample1 = SMOTE()\nOX, Oy = oversample1.fit_resample(X, y)\nplt.figure(figsize=(10, 6))\nplt.plot(OX.loc[Oy == 0, 'std_log_balance'], OX.loc[Oy == 0, 'std_age'], 'b+', label=\"class 0\")\nplt.plot(OX.loc[Oy == 1, 'std_log_balance'], OX.loc[Oy == 1, 'std_age'], 'r*', label=\"class 1\")\nplt.legend()\nplt.xlabel(\"std_log_balance\")\nplt.ylabel(\"std_age\")\nplt.title(\"Scatter Plot by Class (y)\\n After Oversampling using SMOTE\")\nplt.show()",
    "crumbs": [
      "머신러닝2('25 봄)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>빅데이터와 금융자료 분석 기말대체과제</span>"
    ]
  },
  {
    "objectID": "빅데이터_과제.html#question-2",
    "href": "빅데이터_과제.html#question-2",
    "title": "2  빅데이터와 금융자료 분석 기말대체과제",
    "section": "2.2 Question 2",
    "text": "2.2 Question 2\n\n\n\n\n\n\n2.2.1 (1)\n주어진 자료에 K평균 Clustering 알고리즘을 적용하여, 적절한 군집을 생성하여라.\n\ndf = pd.read_csv('data/prob2_card.csv')\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 8950 entries, 0 to 8949\nData columns (total 6 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   CUST_ID              8950 non-null   object \n 1   BALANCE              8950 non-null   float64\n 2   BALANCE_FREQUENCY    8950 non-null   float64\n 3   PURCHASES            8950 non-null   float64\n 4   PURCHASES_FREQUENCY  8950 non-null   float64\n 5   PURCHASES_TRX        8950 non-null   int64  \ndtypes: float64(4), int64(1), object(1)\nmemory usage: 419.7+ KB\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nBALANCE\nBALANCE_FREQUENCY\nPURCHASES\nPURCHASES_FREQUENCY\nPURCHASES_TRX\n\n\n\n\ncount\n8950.000000\n8950.000000\n8950.000000\n8950.000000\n8950.000000\n\n\nmean\n1564.474828\n0.877271\n1003.204834\n0.490351\n14.709832\n\n\nstd\n2081.531879\n0.236904\n2136.634782\n0.401371\n24.857649\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n128.281915\n0.888889\n39.635000\n0.083333\n1.000000\n\n\n50%\n873.385231\n1.000000\n361.280000\n0.500000\n7.000000\n\n\n75%\n2054.140036\n1.000000\n1110.130000\n0.916667\n17.000000\n\n\nmax\n19043.138560\n1.000000\n49039.570000\n1.000000\n358.000000\n\n\n\n\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# CUST_ID는 클러스터링에 사용하지 않으므로 제거\nX = df.drop(columns=[\"CUST_ID\"])\n\n# 표준화\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nscaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n\n# 최적 K 탐색\ninertia_list = []\nsilhouette_list = []\nK_range = range(2, 11)\n\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    labels = kmeans.fit_predict(X_scaled)\n    inertia_list.append(kmeans.inertia_)\n    silhouette_list.append(silhouette_score(X_scaled, labels))\n\nbest_k = K_range[silhouette_list.index(max(silhouette_list))]\n\n# K평균 군집화 결과 : 6개의 군집으로 분류되었으며, 갯수는 32개~3200개로 천차만별\nkmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)\nscaled_df[\"KMeans_Label\"] = kmeans_final.fit_predict(X_scaled)\n\nsummary_table_kmean = scaled_df.groupby(\"KMeans_Label\").mean()\nsummary_table_kmean[\"Count\"] = scaled_df.groupby(\"KMeans_Label\").size()\nsummary_table_kmean\n\n\n\n\n\n\n\n\n\nBALANCE\nBALANCE_FREQUENCY\nPURCHASES\nPURCHASES_FREQUENCY\nPURCHASES_TRX\nCount\n\n\nKMeans_Label\n\n\n\n\n\n\n\n\n\n\n0\n-0.679901\n-2.105347\n-0.305189\n-0.528487\n-0.414547\n1390\n\n\n1\n1.906921\n0.444930\n10.782703\n1.119309\n5.892989\n32\n\n\n2\n-0.331950\n0.368356\n0.087095\n0.960328\n0.227857\n3253\n\n\n3\n-0.068576\n0.366930\n-0.369541\n-0.895659\n-0.502261\n2989\n\n\n4\n0.696282\n0.475045\n2.042474\n1.179006\n2.713984\n502\n\n\n5\n2.320551\n0.483046\n-0.159336\n-0.433551\n-0.273897\n784\n\n\n\n\n\n\n\n\n\n# K평균 군집화 시각화\nsummary_table_kmean.drop(columns=\"Count\").plot.bar(figsize=(12, 6))\nplt.title(\"Standardized Mean of Variables by KMeans Cluster\")\nplt.xlabel(\"Cluster Label\")\nplt.ylabel(\"Standardized Mean Value\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n2.2.2 (2)\n주어진 자료에 DBSCAN Clustering 알고리즘을 적용하여, 적절한 군집을 생성하여라.\n\nfrom sklearn.cluster import DBSCAN\n\n# DBSCAN 분류 : eps 및 min_samples는 여러번 반복을 통해 최적의 조합을 도출하였음.\n# 기준 : 분류가 너무 많거나 적지 않도록(3~6개), 너무 숫자가 적은 분류가 없도록\ndbscan = DBSCAN(eps=0.6, min_samples=4)\nlabels = dbscan.fit_predict(X_scaled)\n\n# 라벨을 데이터프레임에 추가\nscaled_df[\"DBSCAN_Label\"] = labels\n\n# DBSCAN 군집화 결과 : 잡음(-1)이 약 2% 포함되어있으며, 총 5개의 군집으로 분류(177개~6200개)\nsummary_table_db = scaled_df.drop(columns=\"KMeans_Label\").groupby(\"DBSCAN_Label\").mean()\nsummary_table_db[\"Count\"] = scaled_df.groupby(\"DBSCAN_Label\").size()\nsummary_table_db\n\n\n\n\n\n\n\n\n\nBALANCE\nBALANCE_FREQUENCY\nPURCHASES\nPURCHASES_FREQUENCY\nPURCHASES_TRX\nCount\n\n\nDBSCAN_Label\n\n\n\n\n\n\n\n\n\n\n-1\n1.776034\n0.211613\n3.221764\n0.832535\n2.823087\n261\n\n\n0\n-0.056781\n-0.007807\n-0.107234\n-0.028259\n-0.094781\n8657\n\n\n1\n-0.355658\n0.518084\n3.714917\n1.207553\n4.079060\n10\n\n\n2\n-0.397981\n-0.121515\n2.012334\n-0.148985\n-0.169367\n6\n\n\n3\n2.124764\n0.518084\n2.221881\n1.269843\n3.919140\n8\n\n\n4\n4.623668\n0.518084\n0.235086\n0.231676\n-0.199541\n4\n\n\n5\n-0.384296\n0.422144\n4.876114\n1.269843\n3.340815\n4\n\n\n\n\n\n\n\n\n\nsummary_table_db.drop(columns=\"Count\").plot.bar(figsize=(12, 6))\nplt.title(\"Standardized Mean of Variables by DBSCAN Cluster\")\nplt.xlabel(\"Cluster Label\")\nplt.ylabel(\"Standardized Mean Value\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n2.2.3 (3)\n(1)과 (2)의 두 군집 분석 결과를 비교하고, 더 타당한 모델을 선택하여라.\nK평균 vs DBSCAN 군집화 결과 비교\n\n\n\n항목\nK평균\nDBSCAN\n\n\n\n\n클러스터 수\n6개\n6개 (-1 포함)\n\n\n클러스터 구성\n최소 32, 최대 3253명\n최소 4, 최대 8657\n\n\n이상치 처리\n없음\n-1로 261명 처리\n\n\n군집별 특성\n분류기준 명확하\n분류기준 모호, 대부분 하나로 분류\n\n\n시각적 해석력\n변수별 차이 뚜렷\n구분 어려움\n\n\n\n결론 : 이 데이터에서는 K평균이 더 타당한 군집화 방법\n\n\n2.2.4 (4)\n(3)에서 선택된 최종 모델로 생성한 군집들의 고객 특성을 분석하여라.\nK평균 군집화 군집별 특성\n0 : 낮은 자산, 낮은 구매액, 낮은 구매횟수 -&gt; 하위 고객군 (약 17.5%)\n1 : 높은 자산, 높은 구매액, 높은 구매횟수 -&gt; 부유하고 이용량 많은 VIP 고객군 (약 0.5%)\n2 : 평균이하 자산, 평균적인 구매액, 평균이상 구매횟수 -&gt; 일반 고객군 중 상위 이용고객 (약 35%)\n3 : 평균적인 자산, 평균이하 구매액, 평균이하 구매횟수 -&gt; 일반 고객군 중 하위 이용고객 (약 33%)\n4 : 평균적인 자산, 높은 구매액, 높은 구매횟수 -&gt; 평균적이나 카드 사용량이 많은 우량 고객군 (약 5%)\n5 : 높은 자산, 낮은 구매액, 낮은 구매횟수 -&gt; 부유하나 카드를 이용하지 않는 잠재 고객군 (약 9%)\n\n\n2.2.5 (5)\nt-SNE 알고리즘을 적용하여 주어진 자료를 2차원으로 축소하여라. 그 결과를, (3)에서 선택한 모델의 군집 레이블에 따라 점의 색상이 다르게 표현된 2차원 산점도로 시각화하여라.\n\nfrom sklearn.manifold import TSNE\ntsne = TSNE( n_components=2 )\ndf2dim = tsne.fit_transform( X_scaled )\ndf2dim = pd.DataFrame( df2dim, columns=['t1','t2'] )\ndf2dim['Labels' ] = scaled_df[\"KMeans_Label\"]\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=df2dim, x=\"t1\", y=\"t2\", hue=\"Labels\", palette=\"tab10\", s=60, alpha=0.8)\nplt.title(\"2D t-SNE Scatter Plot by Cluster Label\")\nplt.xlabel(\"t-SNE Dimension 1 (t1)\")\nplt.ylabel(\"t-SNE Dimension 2 (t2)\")\nplt.legend(title=\"Cluster Label\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# 참고 : DBSCAN 시각화 결과\ndf2dim['Labels' ] = scaled_df[\"DBSCAN_Label\"]\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=df2dim, x=\"t1\", y=\"t2\", hue=\"Labels\", palette=\"tab10\", s=60, alpha=0.8)\nplt.title(\"2D t-SNE Scatter Plot by Cluster Label\")\nplt.xlabel(\"t-SNE Dimension 1 (t1)\")\nplt.ylabel(\"t-SNE Dimension 2 (t2)\")\nplt.legend(title=\"Cluster Label\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "머신러닝2('25 봄)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>빅데이터와 금융자료 분석 기말대체과제</span>"
    ]
  },
  {
    "objectID": "빅데이터_과제.html#question-3",
    "href": "빅데이터_과제.html#question-3",
    "title": "2  빅데이터와 금융자료 분석 기말대체과제",
    "section": "2.3 Question 3",
    "text": "2.3 Question 3\n\n\n\n\n\n\n2.3.1 (1)\nXGBoost 알고리즘을 적용하여 트리를 생성한다고 할 때, 첫번째 트리의 첫 마디에서 최적의 분리기준이 무엇인지를 구하여라. 단, 결측이 아닌 4개의 관찰치(ID 1~ID 4)만 이용할 것. 제곱오차 손실함수를 적용하며, 모델 초기값 𝑓0는 0.5로 두고, 규제 하이퍼 파라미터 𝜆는 0으로 설정할 것. 또한 계산 과정을 상세하게 서술할 것.\n1. Gradient 및 Hessian 계산\n\n손실함수: \\((y_i - \\hat{y}_i)^2\\)\n예측값: \\(\\hat{y}_i = 0.5\\)\nGradient: \\(g_i = \\hat{y}_i - y_i = 0.5 - y_i\\)\nHessian: \\(h_i = 1\\) (제곱오차 손실함수는 상수)\n\n\n\n\nID\n\\(y_i\\)\n\\(g_i\\)\n\\(h_i\\)\n\n\n\n\n1\n1.25\n-0.75\n1\n\n\n2\n1.20\n-0.70\n1\n\n\n3\n1.30\n-0.80\n1\n\n\n4\n1.50\n-1.00\n1\n\n\n\n\n2. Split 후보 및 Gain 계산\nGain 공식 (\\(\\lambda = 0\\)):\n\\[\n\\text{Gain} = \\frac{1}{2} \\left[ \\frac{G_L^2}{H_L} + \\frac{G_R^2}{H_R} - \\frac{(G_L + G_R)^2}{H_L + H_R} \\right]\n\\]\n\nSplit 1: \\(X \\leq 1.5\\)\n\nLeft: ID 2 → \\(G_L = -0.70\\), \\(H_L = 1\\)\n\nRight: ID 1, 3, 4 → \\(G_R = -2.55\\), \\(H_R = 3\\)\n\n\\[\n\\text{Gain}_1 = \\frac{1}{2} \\left( 0.49 + 2.1675 - 2.640625 \\right) = 0.0084\n\\]\n\nSplit 2: \\(X \\leq 2.5\\)\n\nLeft: ID 2, 3 → \\(G_L = -1.50\\), \\(H_L = 2\\)\n\nRight: ID 1, 4 → \\(G_R = -1.75\\), \\(H_R = 2\\)\n\n\\[\n\\text{Gain}_2 = \\frac{1}{2} \\left( 1.125 + 1.53125 - 2.640625 \\right) = 0.0078\n\\]\n\nSplit 3: \\(X \\leq 3.5\\)\n\nLeft: ID 1, 2, 3 → \\(G_L = -2.25\\), \\(H_L = 3\\)\n\nRight: ID 4 → \\(G_R = -1.00\\), \\(H_R = 1\\)\n\n\\[\n\\text{Gain}_3 = \\frac{1}{2} \\left( 1.6875 + 1 - 2.640625 \\right) = 0.0234\n\\]\n\n결론\n\n\n\nSplit 조건\nGain\n\n\n\n\n\\(X \\leq 1.5\\)\n0.0084\n\n\n\\(X \\leq 2.5\\)\n0.0078\n\n\n\\(X \\leq 3.5\\)\n0.0234\n\n\n\n최적 분리 기준: \\(X \\leq 3.5\\)\n\n\n2.3.2 (2)\nXGBoost 알고리즘을 적용하여 트리를 생성한다고 할 때, 첫번째 트리의 첫 마디에서 X의 값이 결측인 경우는 왼쪽과 오른쪽 자식마디 중 어느 쪽으로 보내야 할지를 결정하여라.\n위의 최적 분할 기준 \\(X \\leq 3.5\\)에 따라, 아래 상황임.\n\nLeft: ID 1, 2, 3 → \\(G_L = -2.25\\), \\(H_L = 3\\)\n\nRight: ID 4 → \\(G_R = -1.00\\), \\(H_R = 1\\)\n\n\n1. 결측이 ID 5인 경우 (\\(Y = 1.4\\))\n\n\\(g_5 = 0.5 - 1.4 = -0.9\\), \\(h_5 = 1\\)\n\nCase A: 왼쪽으로 보낼 경우\n\n\\(G_L = -3.15\\), \\(H_L = 4\\)\n\\(G_R = -1.00\\), \\(H_R = 1\\)\n\n\\[\n\\text{Gain}_{5,\\text{left}} = \\frac{1}{2} \\left( \\frac{(-3.15)^2}{4} + \\frac{(-1)^2}{1} - \\frac{(-4.15)^2}{5} \\right) = 0.0181\n\\]\nCase B: 오른쪽으로 보낼 경우\n\n\\(G_L = -2.25\\), \\(H_L = 3\\)\n\\(G_R = -1.9\\), \\(H_R = 2\\)\n\n\\[\n\\text{Gain}_{5,\\text{right}} = \\frac{1}{2} \\left( \\frac{(-2.25)^2}{3} + \\frac{(-1.9)^2}{2} - \\frac{(-4.15)^2}{5} \\right) = 0.0240\n\\]\n결론: 결측값이 ID 5인 경우, 오른쪽이 더 유리함\n\n2. 결측이 ID 6인 경우 (\\(Y = 1.3\\))\n\n\\(g_6 = 0.5 - 1.3 = -0.8\\), \\(h_6 = 1\\)\n\nCase A: 왼쪽으로 보낼 경우\n\n\\(G_L = -3.05\\), \\(H_L = 4\\)\n\\(G_R = -1.00\\), \\(H_R = 1\\)\n\n\\[\n\\text{Gain}_{6,\\text{left}} = \\frac{1}{2} \\left( \\frac{(-3.05)^2}{4} + \\frac{(-1)^2}{1} - \\frac{(-4.05)^2}{5} \\right) = 0.0229\n\\]\nCase B: 오른쪽으로 보낼 경우\n\n\\(G_L = -2.25\\), \\(H_L = 3\\)\n\\(G_R = -1.8\\), \\(H_R = 2\\)\n\n\\[\n\\text{Gain}_{6,\\text{right}} = \\frac{1}{2} \\left( \\frac{(-2.25)^2}{3} + \\frac{(-1.8)^2}{2} - \\frac{(-4.05)^2}{5} \\right) = 0.0135\n\\]\n결론: ID 6은 왼쪽이 더 유리함\n\n요약\n\n\n\n결측 ID\n\\(Y\\) 값\n왼쪽 Gain\n오른쪽 Gain\n더 나은 방향\n\n\n\n\nID 5\n1.4\n0.0181\n0.0240\n오른쪽\n\n\nID 6\n1.3\n0.0229\n0.0135\n왼쪽",
    "crumbs": [
      "머신러닝2('25 봄)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>빅데이터와 금융자료 분석 기말대체과제</span>"
    ]
  },
  {
    "objectID": "빅데이터_팀프로젝트_팀4_보고서.html",
    "href": "빅데이터_팀프로젝트_팀4_보고서.html",
    "title": "빅데이터와 금융자료분석 프로젝트 (Team 4)",
    "section": "",
    "text": "1. 프로젝트 개요\n본 프로젝트는 여러 데이터 전처리 기법(결측치, 이상치, 특성공학 등)과 머신러닝 알고리즘(이상치 분류, 차원축소, XGBoost 등)을 실제 금융데이터에 적용해보고 시사점을 도출하기 위해 작성되었습니다.\n이를 위해 미국 Lending Club의 P2P 대출 데이터를 사용하였으며, 전반적인 워크플로우는 아래와 같습니다.",
    "crumbs": [
      "머신러닝2('25 봄)",
      "빅데이터와 금융자료분석 프로젝트 (Team 4)"
    ]
  },
  {
    "objectID": "빅데이터_팀프로젝트_팀4_보고서.html#프로젝트-개요",
    "href": "빅데이터_팀프로젝트_팀4_보고서.html#프로젝트-개요",
    "title": "빅데이터와 금융자료분석 프로젝트 (Team 4)",
    "section": "",
    "text": "데이터의 구조, 특성 파악 (EDA)\n데이터의 전처리 (특성에 따른 칼럼 가공, 문자형 변수 처리, 결측치 및 이상치 처리, 변수 선택)\nXGBoost 알고리즘을 이용한 대출 연체여부 예측 모델 구축 및 평가\n\n샘플링, 모델 튜닝, 성과 평가, 변수 중요도 분석(SHAP), Cat/LightGBM 등 다른 모델과 비교",
    "crumbs": [
      "머신러닝2('25 봄)",
      "빅데이터와 금융자료분석 프로젝트 (Team 4)"
    ]
  },
  {
    "objectID": "빅데이터_팀프로젝트_팀4_보고서.html#데이터의-구조-특성-eda",
    "href": "빅데이터_팀프로젝트_팀4_보고서.html#데이터의-구조-특성-eda",
    "title": "빅데이터와 금융자료분석 프로젝트 (Team 4)",
    "section": "2. 데이터의 구조, 특성 (EDA)",
    "text": "2. 데이터의 구조, 특성 (EDA)\n\n데이터의 수집, 기본구조\n미국 소재의 P2P 대출 전문은행인 Lending Club의 ’07~’20년 대출 데이터를 사용하였습니다. (출처 : Kaggle)\n약 40만개의 데이터로, 목적변수인 대출상태를 포함해 전체 27개의 칼럼(수치형 12 + 문자형 15)으로 이루어져있으며, 목적변수는 정상(상환, Fully paid) 및 부도(연체, Charged off)로 이진분류 문제입니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n데이터의 특성\n데이터의 각 칼럼별 특징을 알아보고, 적절한 전처리 방법을 탐색해보았습니다.\n먼저 수치형 변수입니다. 결측치 및 이상치 처리는 별도 진행 예정으로 따로 다루지 않겠습니다.\n상관관계 행렬을 Heatmap으로 살펴보았습니다. 대체적으로 변수들 간 상관관계가 미미하였으며, 일부 상관계수가 높은 변수들은 변수선택 과정에서 제외하는 등 별도의 전처리 과정을 통해 다중공선성 문제를 해결할 계획입니다.\n\n\n\n\n\n다음으로 문자형 변수입니다. 목적변수와 관련이 있는 것으로 보이는 주요 예시만 살펴보겠습니다.\n먼저, 대출기간(term), 집보유형태(home_ownership), 대출목적(purpose)이 영향을 미치는 것으로 추정됩니다.\n\n\n\n\n\n다음으로, 신용등급(A1~G5)에 따라 부도율이 높아지는 추이를 보였으며, 문자형 변수들 중 일부는 고유값이 너무 많아 분석에서 제외하는 것이 효과적일 것으로 보입니다.",
    "crumbs": [
      "머신러닝2('25 봄)",
      "빅데이터와 금융자료분석 프로젝트 (Team 4)"
    ]
  },
  {
    "objectID": "빅데이터_팀프로젝트_팀4_보고서.html#데이터의-전처리",
    "href": "빅데이터_팀프로젝트_팀4_보고서.html#데이터의-전처리",
    "title": "빅데이터와 금융자료분석 프로젝트 (Team 4)",
    "section": "3. 데이터의 전처리",
    "text": "3. 데이터의 전처리\n데이터의 전처리는 아래의 과정으로 실시하였습니다.\n\n분석에 적합하도록 칼럼 변환 및 통합, 제거\n\n변환/통합 : 주소(address)는 우편번호(zip_code)만 추출하고 제거, 대출기간(term, 36month 등)은 수치형으로 변환, 집 소유여부(home_ownership)의 극소수값들은 Other로 통합\n불필요한 noise 방지를 위해 100개 이상의 고유값을 가진 칼럼 제거 : 직업(title), 직업글자수(emp_title), 발행일(issue_d), 최초연도(earliest_cr_line)\n다른 변수와 중복되거나 추론 가능한 칼럼 제거 : 신용점수-대분류(grade), 근속연수(emp_length)\n\n문자형 변수 처리 : 순서가 있거나 이진변수인 경우 라벨인코딩, 단순 점주인 경우 원핫인코딩 적용\n\n라벨인코딩 : 목적변수(이진), 신용점수(순서 존재) / 원핫인코딩 : 이외의 문자형 변수\n\n수치형 변수의 결측치 및 이상치 처리 : 중간값 처리 및 1% 이상치 제거\n\n결측치 : 변수간 상관관계가 미미하고, 이후 Boruta를 적용 예정이므로 예측형 모델보다는 중간값을 채택\n이상치 : 고차원, 많은 샘플(약 40만)을 고려, 분포에 대한 가정이 불필요한 Isolation forest 기법 채택\n\n변수 선택을 통해 분석에 적합한 최종 데이터 가공 : Boruta 알고리즘 적용\n\n일부 변수간 상관관계가 존재하는 점을 고려, 최적의 변수 조합을 찾고자 Boruta 알고리즘 채택\n원핫인코딩 대상 변수를 제외한 13개(수치형+라벨)에 알고리즘을 적용한 결과 11개의 변수를 선택하였고, 원핫인코딩 대상 변수와 결합하여 최종 데이터 구성\n\n\n\n\n\n\n\n\nIsolation Forest 검증(T-SNE 적용) 및 최종 데이터 구성\n\n\n\n수치형 변수에 T-SNE를 적용하여 3차원으로 축소한 결과, 이상치 제거(Isolation Forest)가 적절히 작동하였으며, Boruta 알고리즘으로 변수 선택까지 마친 후 최종 데이터는 7개의 문자형 변수(원핫인코딩 6 + 라벨인코딩 1) 및 9개의 수치형 변수, 1개의 목적변수(이진분류)로 구성되어 있습니다.",
    "crumbs": [
      "머신러닝2('25 봄)",
      "빅데이터와 금융자료분석 프로젝트 (Team 4)"
    ]
  },
  {
    "objectID": "빅데이터_팀프로젝트_팀4_보고서.html#대출-연체여부-예측-모델-구축-및-평가",
    "href": "빅데이터_팀프로젝트_팀4_보고서.html#대출-연체여부-예측-모델-구축-및-평가",
    "title": "빅데이터와 금융자료분석 프로젝트 (Team 4)",
    "section": "4. 대출 연체여부 예측 모델 구축 및 평가",
    "text": "4. 대출 연체여부 예측 모델 구축 및 평가\n\nADASYN을 이용한 오버샘플링\n모델링에 앞서, 클래스 불균형 문제는 ADASYN을 통한 오버샘플링으로 해결하였습니다. 과대평가, 과적합을 방지하고 검증 무결성을 위해 CV 과정의 훈련 데이터에만 오버샘플링하였으며, (imblearn.pipeline 활용) 이를 통해 검증은 항상 원본데이터로만 진행됩니다.\n\n\nXGBoost 모델 구축\n앞서 구성한 40개 변수로 “대출 연체 여부”를 예측하는 모델을 XGBoost 알고리즘을 통해 구축하였으며, 모델 튜닝은 2단계 최적화 접근법을 적용하였습니다. 이러한 방식은 과적합을 방지하고 정해진 계산자원 하에서 최대한 공정하게 파라미터를 비교할 수 있는 장점이 있습니다.\n1단계: 초기 하이퍼파라미터 탐색 - 상대적으로 높은 학습률(0.1)과 고정된 n_estimators 값으로 하이퍼파라미터 조합을 탐색 - 각 조합이 동일한 학습 기회(같은 트리 개수)를 갖도록 보장 (CV 내에서 ADASYN 오버샘플링 적용)\n2단계: 최적 모델 미세 조정 - 1단계에서 찾은 최적 하이퍼파라미터에 낮은 학습률(0.01)과 높은 n_estimators(10000) 적용 - 조기종료를 적용(50)하여 최적의 트리 개수 결정하고, 전체 훈련/검증 데이터를 사용하여 모델 학습\n\n\n\n2단계 접근법의 최종 모델 학습곡선\n\n\n\n\n모델 일반화성능 평가\n클래스 불균형 문제를 고려하여 최종 모델의 일반화 성능을 F1-Score를 중심으로 평가하도록 하겠습니다. F1-score는 약 0.94, ROC-AUC는 약 0.91로 실제 연체 여부를 잘 예측하는 것으로 나타났습니다.\n특히, 모델 튜닝 과정에서 1단계 하이퍼파라미터 탐색시 최고 F1-Score가 0.93544였는데, 일반화 성능은 그와 동일한 수준이므로 과적합 방지를 위한 2단계 최적화 기법이 효과적인 것을 알 수 있습니다.\n\n\n\n\n\n\n\n여러 Gradiant boosting 계열의 알고리즘과 비교\n\n\n\n주로 사용한 XGBoost 이외에도 다양한 Gradiant boosting 계열 및 앙상블 알고리즘이 존재합니다.\n\nXGBoost: Regularization과 트리 구조 최적화에 강점을 가진 Gradient Boosting 모델 |\nCatBoost: 범주형 변수 자동 인식 기능이 있는 Gradient Boosting 기반 모델\nLightGBM: 빠른 학습 속도와 낮은 메모리 사용의 Gradient Boosting 기반 모델\nSoft Voting: CatBoost, LightGBM의 예측 확률 평균을 통한 결합(앙상블) 모델\nStacking: CatBoost, LightGBM의 예측 결과를 Logistic Regression에 전달하는 메타 모델 기반 앙상블\n\nXGBoost와 유사한 방식으로 각 모델을 튜닝, 훈련하였으며 일반화성능은 유사한 수준이였습니다. F1-Score는 앙상블(Soft Voting) 모델이, ROC-AUC 점수는 XGBoost가 가장 우수하였습니다.\n\n\n\n모델\nF1 Score\nROC AUC\n모델\nF1 Score\nROC AUC\n\n\n\n\nCatBoost\n0.9355\n0.9073\nSoft Voting\n0.9356\n0.9072\n\n\nLightGBM\n0.9353\n0.9066\nStacking\n0.9330\n0.9072\n\n\n\n\n\n그러나, 샘플이 적은 “부도”인 경우, 예측 성능이 다소 떨어지는 모습이 관측되었습니다.\n부도의 절반 이상이 정상으로 분류되었으며 모든 모델에 동일한 문제가 있는 것으로 볼 때, 데이터의 한계인 것으로 보입니다. 또는 신경망 계열을 적용해보는 것도 개선방법이 될 수 있습니다.\n\n\n\n\n\n\n\n\n\nXGBoost Confusion Matrix\n\n\n\n\n\n\n\nXGBoost PRCurve\n\n\n\n\n\n\n\n변수 중요도(Feature Importance) 분석\n기본 변수 중요도 산출 결과 부도 여부에는 예상 외로 주거지가 큰 영향을 미치는 것을 확인할 수 있었으며, 이외에도 대출기간 등이 분류에 영향을 미치는 것을 알 수 있었습니다.\n\n\n\n\n\n보다 상세한 변수 중요도 분석을 위해 SHAP(SHapley Additive exPlanations) 분석을 실시하여 각 변수의 중요도, 예측에 미치는 영향(방향성, 정도)을 분석하였습니다.\n\n\n\n\n\n전체적인 중요도는 주거지가 큰 영향을 미친다는 점에서 유사하였으며, 변수별 특징은 아래와 같습니다.\n-   상위 7개는 해당 지역에 주거(1) 시, 연체(0)가 많으므로 집값/소득수준이 낮은 주거지로 추정\n-   하위 2개는 집값/소득수준이 높은 주거지로 추정\n-   대출목적이 부채상환/신용카드, 대출이자가 높고, 대출기간이 길고, 소득이 낮을수록 연체 예측 가능성 증가\n-   이 외에도 대부분의 변수가 대출과 관련된 일반적인 직관과 동일한 것을 알 수 있었음\n\n\n시사점\n이번 프로젝트를 통해 실제 은행의 데이터를 살펴보고, 대출의 부도 확률 예측 모델을 구축해보았습니다.\n먼저 실제 데이터를 전처리하는 과정에서 발생하는 결측치, 이상치, 적합하지 않은 변수 분류 등의 문제점을 실제로 경험할 수 있었고 Isolation Forest 및 T-SNE, Boruta 알고리즘을 적용해보면서 각 알고리즘이 어떻게 작동하는지, 어떤 방식으로 문제를 해결하고 활용되는지 알 수 있었습니다.\n또한, XGBoost 알고리즘이 금융데이터 예측에 강력한 성능을 가진 것을 확인하였고, 모델 성능에는 알고리즘 선택 뿐만아니라 하이퍼파라미터 튜닝 방법(2단계 최적화) 클래스 불균형 해소(oversampling), 변수 선별(boruta) 등이 매우 중요하다는 것을 느꼈습니다.\n결과적으로 은행 대출의 연체여부에는 주거지가 매우 큰 영향을 미친것으로 나타났으며, 이는 주거지에 집값/주거형태/소득/신용점수/직업 등 종합적인 요소가 모두 반영되어있기 때문인 것으로 추정됩니다. 이외에도 이자율, 대출목적/기간 등이 연체 여부 예측에 영향을 미치는 것으로 나타났으며, 그 영향은 일반적인 직관과 동일하였습니다.\n데이터 자체의 한계점으로 인해 소수 표본에 대한 학습이 부족하여 예측력이 다소 떨어지는 한계점이 있었으나, 전반적으로 수업시간에 다룬 여러 알고리즘을 통해 이론이 실제 세상에 적용되는 과정을 이해할 수 있었습니다. 또한, 분석에 적합한 데이터를 구하고 전처리하는 것이 매우 중요하다는 것을 알게 된 프로젝트였습니다.",
    "crumbs": [
      "머신러닝2('25 봄)",
      "빅데이터와 금융자료분석 프로젝트 (Team 4)"
    ]
  },
  {
    "objectID": "사례_과제.html",
    "href": "사례_과제.html",
    "title": "코스피200 변동성 조정 위클리 양매도 전략",
    "section": "",
    "text": "1. 개요\n본 리포트는 옵션과 변동성지수를 활용한 변동성 조정 위클리 양매도전략을 알아보고, 과거 데이터를 통해 구현 및 검증하기 위해 작성되었습니다. 변동성 조정 위클리 양매도란 1.변동성 조정, 2.주단위 매도 두가지 특징을 통해 기존 단점을 보완한 양매도 전략으로, “매주” V-Kospi200를 이용해 행사가격 범위를 결정하고 콜/풋옵션을 매도(양매도)하게 됩니다.\n전략 소개에 앞서 필요한 배경지식을 다루고, 전략 소개 및 구현, 백테스팅 및 성과를 차례로 설명하겠습니다.",
    "crumbs": [
      "사례로 보는 금융공학('25 봄)",
      "코스피200 변동성 조정 위클리 양매도 전략"
    ]
  },
  {
    "objectID": "사례_과제.html#배경지식",
    "href": "사례_과제.html#배경지식",
    "title": "코스피200 변동성 조정 위클리 양매도 전략",
    "section": "2. 배경지식",
    "text": "2. 배경지식\n\n양매도 (Short strangle)\n양매도란 옵션 거래전략으로, 일반적으로 만기일이 같은 외가격(OTM) 콜/풋옵션을 매도하는 것을 의미합니다.\nOTM 옵션을 매도하므로, 만기일에 기초자산의 가격이 풋옵션의 행사가격과 콜옵션의 행사가격 사이라면 권리행사되지 않게 되고 옵션 프리미엄(매도수익)을 그대로 얻을 수 있게 됩니다.\n반면, 양매도는 시장의 변동성이 예상과 달리 큰 경우, 큰 손실이 발생할 수 있다는 단점도 존재합니다. 수익은 프리미엄으로 한정되어있으나, 시황 급변에 따른 옵션 손실에는 제한이 없어 원금 이상의 손실이 발생할 수도 있기 때문입니다.\n즉, 양매도는 높은 확률로 안정적인 중수익을 보장하나 매우 낮은 확률로 큰 손실이 발생할 수 있는 전략이며, 향후 시장의 변동성이 크지 않을 것이라 예측될 때 주로 사용됩니다.\n\n\n\n\n\n\n양매도 전략 예시\n국내의 경우 행사가격의 상하단을 등가격(ATM) \\(\\pm\\) 5%로 설정한 양매도 ETN이 한 때 큰 인기를 끌었습니다. 대표적인 예시인 월별 코스피200 OTM 5% 양매도 전략의 거래방법을 살펴보면, 다음과 같습니다.\n\n현재 코스피200지수를 기준으로 ATM+5%의 콜옵션과 ATM-5%의 풋옵션을 매도 (프리미엄 수익 발생)\n다음달 만기일이 되면, 옵션은 청산(권리행사시 손실)되고 다시 ATM \\(\\pm\\) 5%의 콜,풋옵션을 매도\n\n즉, 월단위로 옵션을 교체하게 되며 행사가격의 상하단은 ATM \\(\\pm\\) 5%로 고정한 양매도 전략입니다. 중위험-중수익으로 흥행에 성공한 상품이지만, 아래와 같은 한계점도 존재합니다.\n\n행사가격 범위가 고정되어있어 변동성 확대시 손실 가능성이 커지고, 변동성 축소시 프리미엄 수익이 크게 감소\n옵션 교체주기가 1개월로, 그간 지수의 하락이 누적된다면 손실이 과도하게 커질 수 있음 (유동성 리스크)\n\n\n\n\n코스피200 변동성지수 (V-Kospi200 index)\n코스피200 변동성 지수란 주식 시장의 변동성을 측정하는 지표입니다. 코스피200 옵션 가격 기반의 내재변동성을 이용하여 산출되며, 향후 30일간 시장 변동성에 대한 투자자들의 기대를 나타내는 지수입니다.\n\n주요 특징\n\n시장 심리 반영: 투자자들의 불안 심리를 반영하며, ’공포 지수(Fear Index)’라고도 불림\n옵션 가격 기반: 코스피200 옵션 가격 기반의 내재변동성을 통해 산출되며, 여기에는 투자자들의 기대가 반영\n\n그래프1 : 일별 코스피200지수 및 코스피200 변동성지수\n\n\n\n\n\n\n\n\n코스피200 위클리옵션\n코스피200 위클리옵션이란 코스피200 지수를 기초자산으로 하는 주간 단위의 옵션 거래 상품을 말합니다. ’19년 상장되었으며 기존의 월 단위 만기가 도래하는 옵션과는 달리, 매주 월/목요일에 만기가 도래하는 단기 옵션입니다.\n\n주요 특징\n\n세밀한 거래 지원: 매주 월/목요일에 만기가 도래하여 단기적인 시장 변동에 대한 투자 및 위험 관리에 유리\n다양한 투자 전략 활용: 단기적인 시장 예측을 기반으로 다양한 투자 전략을 구사할 수 있습니다.",
    "crumbs": [
      "사례로 보는 금융공학('25 봄)",
      "코스피200 변동성 조정 위클리 양매도 전략"
    ]
  },
  {
    "objectID": "사례_과제.html#전략-소개-및-구현",
    "href": "사례_과제.html#전략-소개-및-구현",
    "title": "코스피200 변동성 조정 위클리 양매도 전략",
    "section": "3. 전략 소개 및 구현",
    "text": "3. 전략 소개 및 구현\n\n전략 개요\n변동성 조정 위클리 양매도(Volatility Adjusted Weekly Short strangle, VWss) 전략이란, 기존에 널리 활용되던 월별 OTM 5% 양매도 전략에 아래 두가지 방법을 결합한 전략을 의미합니다.\n\n옵션의 교체주기를 “매월” -&gt; “매주” 단위로 세분화\n행사가격의 범위를 고정하는 것이 아니라 매 옵션 매도시점마다 시장 변동성을 고려하여 조정\n\n따라서, 기존과 달리 주단위로 옵션을 교체하며, 행사가격의 범위는 교체시점에 매번 달라지게 됩니다. 이를 위해 코스피200위클리옵션을 사용하고, 변동성 지표는 내재변동성 기반의 V-Kospi200지수를 사용**하여 구현할 계획입니다.\n\n\n행사가격 범위 설정방법\n행사가격의 상하단은 옵션 매도시점의 “전일 V-Kospi200 종가”를 참조하여 설정할 예정입니다. V-Kospi200는 향후 30일간 코스피200 지수의 변동성을 수치화한 지표로서, 현재시점에서 변동성을 잘 예측할 수 있는 수단이기 때문입니다.\n다만, 본 전략에서 옵션 매도포지션의 유지기간은 약 7일이므로 지수 종가(연율)를 주단위 기간에 맞도록 환산하여 행사가격의 상하단을 산출하였습니다.\n\\[\\sigma_{Target}\\;=\\;\\frac{VKospi200_{(T-1)}\\times\\sqrt{Calendar\\;days}}{\\sqrt{365}}\\]\n\\[Call\\;strike\\;=\\;Kospi200_{(T)}\\times (1+\\sigma_{Target})\\;rounded\\;up\\;to\\;2.5pt\\]\n\\[Put\\;strike\\;=\\;Kospi200_{(T)}\\times (1-\\sigma_{Target})\\;rounded\\;down\\;to\\;2.5pt\\]\n이렇게 행사가격을 설정하면 V-Kospi200가 15pt일 때 월환산 변동성이 약 5%(주환산 2.5%)가 됩니다. 즉,\n\n시장의 예상 변동성(V-Kospi200)이 연 15% 이상 -&gt; 행사가격 범위를 기존보다 넓게 설정하여 손실 가능성 축소\n시장의 예상 변동성이 연 15% 미만 -&gt; 행사가격 범위를 기존보다 좁게 설정하여 프리미엄 수익 극대화\n\n\n\n\n\n\n\n본 전략은 위클리옵션을 사용하므로 향후 1주일 변동성이 필요합니다. 따라서, 30일 변동성을 나타내는 V-Kospi200은 만기 mismatch가 있지만, 단기간의 예측치에는 큰 차이가 없고 이외의 대안(e.g. 7-day VIX)이 없어 V-Kospi200를 그대로 사용하였습니다.\n\n\n\n\n\n포트폴리오 구성 방법\n먼저, 편의를 위해 세금/수수료/호가스프레드 등의 거래비용은 없으며 종가에 원하는 수량만큼 거래할 수 있는 완전자본시장을 가정하도록 하겠습니다. 전략 구현을 위한 포트폴리오(투자원금 100억원) 구성 과정은 아래와 같습니다.\n\n전일 V-Kospi200 지수를 주단위로 환산하여 예상변동성(\\(\\hat\\sigma=(VKospi200\\times \\sqrt{day})/\\sqrt{365}\\)) 산출\n예상변동성을 당일 Kospi200지수에 적용하여 행사가격 상하단(ATM \\(\\pm\\hat\\sigma\\)을 2.5pt 단위로 올림/내림) 산출\n당일 Kospi200지수 및 승수(25만)를 적용, 옵션 매도수량(\\(Q_{sell}=nominal/(kospi200\\times multiplier)\\)) 산출\n행사가격 상단 콜옵션, 하단 풋옵션 매도 (\\(Premium=(call price+put price)\\times Q_{sell}\\times multiplier\\))\n원금과 매도수익을 다음주 만기일까지 MMF에 투자 (\\(Interest=(nominal+Premium)\\times MMF \\times \\frac{day}{365}\\))\n다음주 만기일이 되면, 권리행사 손실을 포함하여 최종손익 산출(\\(Revenue=Premium+Interest-Exercise\\))\n\nKospi200 &gt; 행사가격 상단, 콜옵션에서 손실 발생(\\(Exercise=(Kospi200-Strike_{call})\\times multiplier\\))\nKospi200 &lt; 행사가격 하단, 풋옵션에서 손실 발생(\\(Exercise=(Strike_{put}-Kospi200)\\times multiplier\\))\n이외의 경우, 권리행사되지 않아 옵션 포지션 청산(\\(Exercise=0\\))\n\n주간 최종손익을 정산(\\(nominal_{new}=nominal_{old}+Revenue\\))하고, 투자종료시점까지 1. ~ 6. 과정을 반복",
    "crumbs": [
      "사례로 보는 금융공학('25 봄)",
      "코스피200 변동성 조정 위클리 양매도 전략"
    ]
  },
  {
    "objectID": "사례_과제.html#backtesting",
    "href": "사례_과제.html#backtesting",
    "title": "코스피200 변동성 조정 위클리 양매도 전략",
    "section": "3. Backtesting",
    "text": "3. Backtesting\n\n데이터 수집 및 전처리, 포트폴리오 구현\n과거 5개년(2020~2024) 코스피200 등의 지수/옵션 가격, 금리를 수집하였으며, 출처는 아래와 같습니다.\n한국거래소 정보데이터시스템(data.krx.co.kr) : 코스피200 및 V-Kospi200지수\n한국거래소 OpenAPI(openapi.krx.co.kr) : 코스피200옵션 및 위클리옵션 종목별 가격\n한국은행 경제통계시스템(ecos.bok.or.kr) : 일별 MMF(7일) 금리\n\n\n\n\n\n\n한국거래소 OpenAPI를 활용한 데이터 수집 예시\n\n\n\n\n\n\n\n\nAPI 호출시 json 데이터를 수집할 수 있으며, 이를 Dataframe(python) 및 tibble(r)로 변환하여 활용하였습니다.\n\nimport requests; import json\nurl = 'http://data-dbg.krx.co.kr/svc/sample/apis/drv/opt_bydd_trd?basDd=20250312'\nheaders = {'AUTH_KEY': '74D1B99DFBF345BBA3FB4476510A4BED4C78D13A'}\nres = requests.get(url=url, headers=headers); res.text\n\n'{\"OutBlock_1\":[{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3195\",\"ISU_NM\":\"코스피200 C 202503 195.0\",\"TDD_CLSPRC\":\"145.90\",\"CMPPREVDD_PRC\":\"6.85\",\"TDD_OPNPRC\":\"144.95\",\"TDD_HGPRC\":\"146.10\",\"TDD_LWPRC\":\"144.95\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"145.90\",\"ACC_TRDVOL\":\"31\",\"ACC_TRDVAL\":\"1129625000\",\"ACC_OPNINT_QTY\":\"154\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3197\",\"ISU_NM\":\"코스피200 C 202503 197.5\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"143.40\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"0\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3200\",\"ISU_NM\":\"코스피200 C 202503 200.0\",\"TDD_CLSPRC\":\"140.60\",\"CMPPREVDD_PRC\":\"5.00\",\"TDD_OPNPRC\":\"140.00\",\"TDD_HGPRC\":\"141.15\",\"TDD_LWPRC\":\"139.95\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"140.60\",\"ACC_TRDVOL\":\"31\",\"ACC_TRDVAL\":\"1088750000\",\"ACC_OPNINT_QTY\":\"290\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3202\",\"ISU_NM\":\"코스피200 C 202503 202.5\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"138.40\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"0\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3205\",\"ISU_NM\":\"코스피200 C 202503 205.0\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"135.90\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"0\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3207\",\"ISU_NM\":\"코스피200 C 202503 207.5\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"133.40\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"0\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3210\",\"ISU_NM\":\"코스피200 C 202503 210.0\",\"TDD_CLSPRC\":\"130.60\",\"CMPPREVDD_PRC\":\"5.60\",\"TDD_OPNPRC\":\"130.60\",\"TDD_HGPRC\":\"130.60\",\"TDD_LWPRC\":\"130.60\",\"IMP_VOLT\":\"64.00\",\"NXTDD_BAS_PRC\":\"130.60\",\"ACC_TRDVOL\":\"1\",\"ACC_TRDVAL\":\"32650000\",\"ACC_OPNINT_QTY\":\"20\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3212\",\"ISU_NM\":\"코스피200 C 202503 212.5\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"62.47\",\"NXTDD_BAS_PRC\":\"128.40\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"0\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3215\",\"ISU_NM\":\"코스피200 C 202503 215.0\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"60.94\",\"NXTDD_BAS_PRC\":\"125.90\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"59\"},{\"BAS_DD\":\"20250312\",\"PROD_NM\":\"코스피200 옵션\",\"RGHT_TP_NM\":\"CALL\",\"ISU_CD\":\"201W3217\",\"ISU_NM\":\"코스피200 C 202503 217.5\",\"TDD_CLSPRC\":\"-\",\"CMPPREVDD_PRC\":\"-\",\"TDD_OPNPRC\":\"-\",\"TDD_HGPRC\":\"-\",\"TDD_LWPRC\":\"-\",\"IMP_VOLT\":\"59.42\",\"NXTDD_BAS_PRC\":\"123.40\",\"ACC_TRDVOL\":\"0\",\"ACC_TRDVAL\":\"0\",\"ACC_OPNINT_QTY\":\"0\"}]}'\n\n\n\n\n수집한 데이터는 R을 이용하여 전처리하였으며, 두개의 데이터셋으로 요약하였습니다.\n\n포트폴리오 기본 정보 : 옵션 만기일(매주), 옵션 보유일, MMF금리, Kospi200, 전일 V-K200, 거래대상옵션 정보\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBAS_DD\nVOL\nDIFF_DAY\nMMF\nKOSPI200\nLAG_VK200\nPRIOR\nTARGET_C_K\nTARGET_P_K\n\n\n\n\n20241219\n0.0248719\n7\n0.0334\n322.38\n17.96\n24124\n332.5\n312.5\n\n\n20241212\n0.0285279\n7\n0.0335\n329.04\n20.60\n24123\n340.0\n317.5\n\n\n20241205\n0.0295527\n7\n0.0341\n323.87\n21.34\n24122\n335.0\n312.5\n\n\n20241128\n0.0252043\n7\n0.0340\n331.45\n18.20\n24121\n340.0\n322.5\n\n\n20241121\n0.0276001\n7\n0.0344\n329.49\n19.93\n24114\n340.0\n320.0\n\n\n20241114\n0.0344274\n7\n0.0340\n317.70\n24.86\n24113\n330.0\n305.0\n\n\n\n\n\n\n거래대상옵션 정보 : 포트폴리오 기본 정보에 대응되는 거래대상옵션의 종가, 거래량(0인 경우 제외)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBAS_DD\nPRICE_TARGET_C_K\nPRICE_TARGET_P_K\nACC_TRDVOL_TARGET_C_K\nACC_TRDVOL_TARGET_P_K\n\n\n\n\n20241219\n0.29\n0.74\n343\n137\n\n\n20241212\n0.42\n0.78\n190\n196\n\n\n20241205\n0.44\n0.91\n65452\n51417\n\n\n20241128\n0.34\n0.43\n288\n201\n\n\n20241121\n0.37\n0.53\n115\n201\n\n\n20241114\n0.43\n0.74\n329\n165\n\n\n\n\n\n이를 통해 매도수량, 프리미엄, 이자수익, 권리행사손실 등을 산출하여 포트폴리오를 구현하였습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBAS_DD\nVOL\nSELL_AMT\nPREMIUM\nINTEREST\nEXERCISE\nREVENUE\nRATE\n\n\n\n\n20200102\n0.0203434\n137.7648\n29963837\n2789154\n0\n32752991\n0.0032753\n\n\n20200109\n0.0221160\n135.8650\n20040080\n2844044\n9510547\n13373578\n0.0013374\n\n\n20200116\n0.0185154\n132.1091\n18825550\n2824485\n0\n21650035\n0.0021650\n\n\n20200123\n0.0197895\n132.3058\n23815037\n2787444\n219296795\n-192694314\n-0.0192694\n\n\n20200130\n0.0235286\n138.7107\n45080972\n2793358\n109234664\n-61360333\n-0.0061360\n\n\n20200206\n0.0252458\n133.0451\n46565774\n2774504\n0\n49340278\n0.0049340\n\n\n\n\n\n\n\n\n\n\n\n\n변동성 조정 방법에 따른 행사가격 범위 추이(과거 5년)\n\n\n\nV-Kospi200과 연동한 행사가격의 범위는 지난 5년간 1.6% ~ 8.7%까지 광범위하게 형성되었습니다.\n코스피200이 급등락하는 경우 범위가 넓게 형성되고 보합장에서는 좁게 형성되는 추이를 확인할 수 있으며, 이를 월환산(\\(\\times\\sqrt{4}\\))하여 기존 5%와 비교하면 지수의 상황에 따라 유동적으로 조절되고 있음을 의미합니다.\n\n\n그래프2 : 월평균 코스피200지수(적색) 및 행사가격 범위(청색)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacktesting 성과\n지난 5년간(2020~2024) VW양매도와 코스피200지수 / OTM 5% 양매도를 비교해보았습니다.\n표1 : 연도별 변동성 조정 위클리 양매도 포트폴리오 및 코스피200지수 성과\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nExpiry\nNoExercise\nPremium\nInterest\nLoss\nRevenue\nReturn\nReturn_K200\n\n\n\n\n2020\n50\n0.74\n4385\n184\n5338\n-769\n-0.04\n0.33\n\n\n2021\n47\n0.91\n2974\n142\n728\n2387\n0.12\n0.01\n\n\n2022\n52\n0.79\n3304\n421\n4152\n-427\n-0.03\n-0.26\n\n\n2023\n52\n0.81\n2456\n732\n1758\n1430\n0.08\n0.23\n\n\n2024\n49\n0.80\n3697\n719\n3454\n962\n0.05\n-0.11\n\n\n\n\n\n표2 : 연도별 일반 양매도 포트폴리오 및 코스피200지수 성과\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nExpiry\nNoExercise\nPremium\nInterest\nLoss\nRevenue\nReturn\nReturn_K200\n\n\n\n\n2020\n12\n0.58\n16507\n847\n37851\n-20497\n-0.23\n0.33\n\n\n2021\n12\n1.00\n9887\n605\n0\n10492\n0.13\n0.01\n\n\n2022\n12\n0.50\n10207\n1819\n15098\n-3071\n-0.04\n-0.26\n\n\n2023\n12\n0.83\n4591\n3176\n884\n6883\n0.09\n0.23\n\n\n2024\n12\n0.75\n9850\n3072\n9589\n3333\n0.04\n-0.11\n\n\n\n\n\n\n\n\n\n\n\nYEAR : 산출대상 연도 / Expiry : 옵션만기 횟수 (프리미엄 수익 발생 횟수)\nNoExercise : 옵션만기일에 행사되지 않은 비율 (손실이 발생하지 않은 거래일 비율)\nPremium : 평균 옵션 프리미엄 수익 (만원) / Interest : 원금 및 프리미엄에서 발생한 평균 이자수익 (만원)\nLoss : 옵션권리행사로 인한 평균 손실 (미행사 포함) / Revenue : 평균 이익 (Premium + Interest - Loss)\nReturn : 포트폴리오의 연환산 수익률 / Return_K200 : 코스피200지수의 연환산 수익률\n\n\n\n변동성 조정 위클리 양매도 포트폴리오의 주요 성과는 다음과 같습니다.\n\n옵션 매도주기 축소(월간 \\(\\rightarrow\\) 주간) : 현금흐름 개선 및 프리미엄 수익 극대화\n\n\nVW양매도 포트폴리오는 연평균 50회의 수익이 발생하는 반면, 일반 양매도 포트폴리오는 12회(월1회) 발생.\n1회 발생 수익은 4배 미만으로 감소하여 평균 수익이 증가하였고, 수익주기가 짧아지면서 현금유동성 개선\n\n\n행사가격 범위 조정(5% \\(\\rightarrow\\) \\(\\sigma\\)연동) : 포트폴리오 안정성 증가 및 리스크 축소\n\n\n일반 양매도 전략의 손실발생비율(권리행사비율)은 시장 상황에 따라 0~50%까지 큰 폭으로 변동\n반면, 본 포트폴리오는 행사가격 범위를 변동성 수준에 조정하므로 비율이 10~30%수준으로 안정화\n손실에 대한 예측가능성 및 포트폴리오 변동성이 개선되었으며 1회 손실도 감내 가능한 수준으로 축소\n\n\n소결 : VW양매도 전략은 수익률, 리스크 측면에서 코스피200지수 및 일반 양매도 전략을 Outperform\n\n\n그래프3, 4 : 지난 5년 및 3년간 코스피200지수, VW양매도, 5%양매도 누적수익률 및 초과수익\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n표3 : 연도별 VW양매도, 일반 양매도, 코스피200지수의 수익률 및 변동성(월간수익률의 연환산)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nReturn_main\nReturn_sub\nReturn_K200\nVol_main\nVol_sub\nVol_K200\n\n\n\n\n2020\n-0.04\n-0.23\n0.33\n0.08\n0.19\n0.27\n\n\n2021\n0.12\n0.13\n0.01\n0.03\n0.02\n0.11\n\n\n2022\n-0.03\n-0.04\n-0.26\n0.08\n0.08\n0.25\n\n\n2023\n0.08\n0.09\n0.23\n0.04\n0.01\n0.17\n\n\n2024\n0.05\n0.04\n-0.11\n0.07\n0.08\n0.16\n\n\n\n\n\n그래프와 표를 통해 VW양매도 전략이 타 전략 대비 안정적이고 높은 수익을 실현하였음을 확인할 수 있었습니다.\n\n\n한계점\n그러나, 행사가격 범위가 전일 V-Kospi200 지수에 따라 결정되므로 옵션 매도일 및 보유기간 중 V-Kospi200 지수가 급등락하는 경우 시장 변동성을 적절히 반영되지 않을 가능성이 있습니다.\n\n당일 장중 지수를 사용할 수 있겠으나 종가보다 신뢰성이 높다고 보기 어렵고, 당일 종가는 매도시점에서 확인 불가\n보유기간 중 V-Kospi200의 변동에 따라 옵션 행사가격을 리밸런싱하면 보다 정확히 변동성을 반영할 수 있으나, 잦은 거래로 인해 수반되는 비용이 급증\n시장 변동성이 적절히 반영되지 않는 경우, 프리미엄 수익성이 낮아지고 옵션 권리행사 위험이 증가할 수 있음\n\n또한, 실제로 VW양매도 포트폴리오를 운영한다면 거래비용 및 유동성 등의 한계점으로 인해 보완해야할 점이 있으며 이 과정에서 초과수익률 등의 성과가 다소 희석될 것으로 예상됩니다.\n\n수수료/유동성 등으로 인해 자주 옵션을 매도하는 전략 특성상 거래비용 상승이 수반됨\n월물 옵션 대비 위클리옵션의 유동성이 낮아, 변동성 확대 국면에서 원하는 위클리옵션의 거래가 없을 수 있음",
    "crumbs": [
      "사례로 보는 금융공학('25 봄)",
      "코스피200 변동성 조정 위클리 양매도 전략"
    ]
  },
  {
    "objectID": "사례_과제.html#포트폴리오-검증-25.3.13-4.10",
    "href": "사례_과제.html#포트폴리오-검증-25.3.13-4.10",
    "title": "코스피200 변동성 조정 위클리 양매도 전략",
    "section": "4. 포트폴리오 검증 (’25.3.13 ~ 4.10)",
    "text": "4. 포트폴리오 검증 (’25.3.13 ~ 4.10)\n포트폴리오의 성과 검증을 위해 ’25년 3월 옵션만기일부터 1개월간의 성과를 측정해보겠습니다.\nBacktesting과 동일한 방식으로 진행하였으며, 날짜 등 일부를 제외하고 동일 코드를 재사용하였습니다.\n표4 : 검증기간(’25.3.13 ~ 4.10) VW양매도 및 일반 양매도 전략 성과\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBAS_DD\nGroup\nPremium\nInterest\nLoss\nRevenue\nReturn\n\n\n\n\n20250313\nMonthly\n12653\n2400\n0\n15053\n0.02\n\n\n20250313\nVol-adj. Weekly\n5624\n596\n2929\n3291\n0.00\n\n\n20250320\nVol-adj. Weekly\n2687\n587\n0\n3274\n0.00\n\n\n20250327\nVol-adj. Weekly\n4283\n578\n20214\n-15353\n-0.02\n\n\n20250403\nVol-adj. Weekly\n11594\n578\n0\n12173\n0.01\n\n\n81001363\nVol-adj. Weekly Sum\n24188\n2338\n23142\n3384\n0.00\n\n\n\n\n\n검증기간 중 VW양매도 전략은 옵션을 4회 매도하였고, 일반 양매도는 1회 매도하였습니다.\nVW양매도 전략의 프리미엄이 4회 발생하면서 수익성은 개선되었지만, 세번째 매도시기에 큰 손실이 발생하면서 순이익이 악화되었습니다. 벡테스팅 결과와 비교할 때 상반된 결과입니다.\n그 원인은 최근 트럼프 행정부의 관세 부과 정책의 영향으로, 증시가 이례적으로 급등락한 데에서 찾을 수 있었습니다.\n\n그래프5 : 검증기간(’25.3.13 ~ 4.10) Kospi200 및 V-Kospi200 지수 추이\n\n\n\n\n\n\n\n\n\n먼저, 3.27일 예상변동성(V-K200)이 낮아 행사가격 범위가 좁게 형성되어 VW양매도 전략이 실행되었고, 이후 관세 정책 영향으로 지수가 급락하면서 큰 손실이 발생하게 되었습니다.\n반면 월별 전략은 만기 직전에 관세가 연기되면서 증시가 회복하였고(304 &gt; 325), 손실을 피하게 되었습니다.\n다소 아쉬운 결과이나, VW양매도 전략의 한계점과 특수한 상황에서는 오히려 불리하다는 점을 알 수 있었습니다.\n\nVW양매도 전략은 시장 변동성이 적절히 반영되지 않을 가능성이 있고, 이 경우 예기치 못한 손실이 발생할 수 있음\n옵션 만기가 짧은 것은 일반적으로 수익성, 유동성 등에서 장점이 있으나, 증시가 급락 후 회복하는 상황에서는 만기가 긴 옵션이 유리할 수 있음",
    "crumbs": [
      "사례로 보는 금융공학('25 봄)",
      "코스피200 변동성 조정 위클리 양매도 전략"
    ]
  },
  {
    "objectID": "사례_과제.html#appendix-python-r-code",
    "href": "사례_과제.html#appendix-python-r-code",
    "title": "코스피200 변동성 조정 위클리 양매도 전략",
    "section": "5. Appendix : Python, R code",
    "text": "5. Appendix : Python, R code\n\nPyhon code : 데이터 수집 및 전처리\n\nimport requests\nimport json\nimport pandas as pd\nimport aiohttp\nimport asyncio\n\n# KRX OpenAPI 예시\nurl = 'http://data-dbg.krx.co.kr/svc/sample/apis/drv/opt_bydd_trd?basDd=20250312'\nheaders = {'AUTH_KEY': '74D1B99DFBF345BBA3FB4476510A4BED4C78D13A'}\nres = requests.get(url=url, headers=headers)\nres.text\n\n# KRX OpenAPI를 이용한 옵션 데이터 수집 (네트워크 병렬 처리)\nidx_data = pd.read_csv('data/idx_data.csv')\nurl = 'http://data-dbg.krx.co.kr/svc/apis/drv/opt_bydd_trd?basDd='\nkey = 'BDFA640BBCE84C4B8A465EA024D50D6F3FD909FF'\n\nasync def fetch(session, url, bas_dd):\n    async with session.get(url + bas_dd, headers={'AUTH_KEY': key}) as response:\n        return await response.json()\n\nasync def fetch_all(bas_dd_list, url):\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch(session, url, str(bas_dd)) for bas_dd in bas_dd_list]\n        return await asyncio.gather(*tasks)\n\nasync def main():\n    bas_dd_list = idx_data['BAS_DD'].astype(str).tolist()\n    responses = await fetch_all(bas_dd_list, url)\n\n    data_list = [pd.json_normalize(res['OutBlock_1']) for res in responses if 'OutBlock_1' in res and res['OutBlock_1']]\n    options = pd.concat(data_list, axis=0, ignore_index=True)\n\n    # CSV 저장\n    options.to_csv(\"options_data.csv\", encoding=\"utf-8-sig\", index=False)\n    print(\"complete\")\n\n\n\nR code 1 : 데이터 가공, Backtesting\n\nrm(list=ls())\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(patchwork)\n\n# 1. 원본데이터 준비\noptions_raw &lt;- read_csv(\"data/options_data.csv\") %&gt;% tibble()\nidx_raw &lt;- read_csv(\"data/idx_data.csv\") %&gt;% tibble()\nmmf_raw &lt;- read_csv(\"data/mmf.csv\") %&gt;% tibble()\n\n# 2-1. 데이터 전처리 : KRX openAPI 옵션데이터 전처리\noptions &lt;- options_raw %&gt;% \n  # K200, WK200 이외의 옵션 제외\n  filter(substr(PROD_NM,1,3)==\"코스피\") %&gt;%\n  # 종가가 없는 경우 익일 기준가격(이론가격) 사용\n  mutate(PRICE = as.double(if_else(TDD_CLSPRC==\"-\",NXTDD_BAS_PRC,TDD_CLSPRC))) %&gt;% \n  drop_na(PRICE) %&gt;% \n  select(BAS_DD,ISU_NM,PRICE,ACC_TRDVOL) %&gt;% \n  separate(ISU_NM, into=c(\"PROD\",\"RGHT\",\"EXP\",\"EXER_PRC\"), sep=' ') %&gt;%\n  mutate(EXER_PRC=as.double(EXER_PRC),\n         EXPMM=if_else(PROD==\"코스피200\",substr(EXP,3,6),substr(EXP,1,4)),\n         EXPWW=if_else(PROD==\"코스피200\",2,as.integer(substr(EXP,6,6)))) %&gt;% \n  filter(EXER_PRC&gt;min(idx_raw$KOSPI200)*0.85,\n         EXER_PRC&lt;max(idx_raw$KOSPI200)*1.15,\n         PROD!=\"코스피위클리M\") %&gt;% # 월요일 만기 위클리옵션 제외\n  mutate(PRIOR=as.integer(EXPMM)*10+EXPWW) # 만기가 짧은 순으로 우선순위 부여\n\n# 2-2. 데이터 전처리 : 옵션 만기일 데이터 생성\ntarget_date &lt;- options %&gt;% \n  distinct(.,BAS_DD, PRIOR) %&gt;% \n  arrange(PRIOR, desc(BAS_DD)) %&gt;% \n  group_by(PRIOR) %&gt;% \n  slice(1) %&gt;% \n  ungroup() %&gt;% \n  distinct(BAS_DD) %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  filter(BAS_DD&lt;20241231, BAS_DD&gt;20200101)\n\n# 2-3. 데이터 전처리 : KRX 정보데이터시스템 K200 및 V-K200지수 전처리\nidx_data &lt;- idx_raw %&gt;%\n  arrange(BAS_DD) %&gt;% \n  mutate(LAG_K200=lag(KOSPI200),\n         LAG_VK200=lag(VKOSPI200))\n\nK200_portfolio=idx_data %&gt;% \n  left_join(mmf_raw, by=\"BAS_DD\") %&gt;% \n  mutate(RATE=(KOSPI200-LAG_K200)/LAG_K200,\n         YEAR = substr(BAS_DD, 1, 4),\n         YM = ym(substr(BAS_DD, 1, 6))) %&gt;%\n  group_by(YEAR, YM) %&gt;%\n  summarise(RATE_K200 = if_else(is.na(prod(1 + RATE)),0,prod(1 + RATE)),\n            MMF = mean(MMF)/100,\n            .groups = \"drop\") %&gt;%\n  ungroup()\n\n# 3-1. 포트폴리오 구성 : VW양매도 포트폴리오 기초정보 생성\ntarget_info &lt;- target_date %&gt;% \n  left_join(options, by=\"BAS_DD\") %&gt;% \n  distinct(BAS_DD,PRIOR) %&gt;% \n  arrange(desc(BAS_DD),PRIOR) %&gt;% \n  group_by(BAS_DD) %&gt;% \n  # 만기가 도래하는 옵션을 제외하고 우선순위가 높은 옵션 선택\n  slice(2) %&gt;% \n  ungroup() %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  left_join(idx_data, by=\"BAS_DD\") %&gt;% \n  left_join(mmf_raw, by=\"BAS_DD\") %&gt;% \n  # 옵션 보유기간 및 단기금리(MMF) 계산\n  mutate(DIFF_DAY=as.integer(ymd(lag(BAS_DD))-ymd(BAS_DD)),\n         MMF=MMF*0.01) %&gt;% \n  # 옵션 보유기간에 해당하는 시장기대변동성 계산(V-K200활용)\n  mutate(VOL=LAG_VK200*sqrt(DIFF_DAY)/sqrt(365)/100) %&gt;%\n  # 변동성에 따른 옵션 행사가격 상단(2.5단위 올림) 및 하단(2.5단위 내림) 계산\n  mutate(TARGET_C_K=ceiling(KOSPI200*(1+VOL)*0.4)/0.4,\n         TARGET_P_K=floor(KOSPI200*(1-VOL)*0.4)/0.4) %&gt;% \n  drop_na(DIFF_DAY) %&gt;% \n  select(BAS_DD,VOL,DIFF_DAY,MMF,KOSPI200,LAG_VK200,PRIOR,TARGET_C_K,TARGET_P_K)\n\n# 3-2. 포트폴리오 구성 : VW양매도 포트폴리오 거래대상 옵션 정보 생성\ntarget_options &lt;- target_info %&gt;% \n  select(BAS_DD, PRIOR, TARGET_C_K, TARGET_P_K) %&gt;% \n  pivot_longer(cols=c(\"TARGET_C_K\",\"TARGET_P_K\"),names_to = \"GRP\", values_to = \"EXER_PRC\") %&gt;% \n  mutate(RGHT=substr(GRP,8,8)) %&gt;% \n  left_join(options,by=c(\"BAS_DD\",\"PRIOR\",\"RGHT\",\"EXER_PRC\")) %&gt;%\n  select(BAS_DD,GRP,PRICE,ACC_TRDVOL) %&gt;% \n  pivot_wider(names_from = \"GRP\", values_from = c(\"PRICE\",\"ACC_TRDVOL\"))\n\n# 원금 100억원 가정\ncash = 10000*10000*100\n\n# 4. 포트폴리오 구현 : VW양매도 전략을 구현하여 일자별 손익 계산\nportfolio &lt;- target_info %&gt;% \n  left_join(target_options,by=\"BAS_DD\") %&gt;% \n  arrange(BAS_DD) %&gt;% \n  # 원금에 따른 옵션 매도수량 계산\n  mutate(SELL_AMT=cash/250000/KOSPI200) %&gt;% \n  # 옵션 프리미엄(매도수익)) 계산\n  mutate(PREMIUM=SELL_AMT*(PRICE_TARGET_C_K+PRICE_TARGET_P_K)*250000) %&gt;% \n  # 원금 및 프리미엄의 MMF 이자수익 및 권리행사손실 계산\n  mutate(INTEREST=(cash+replace_na(PREMIUM,0))*MMF*DIFF_DAY/365,\n         EXERCISE=(if_else(lead(KOSPI200)-TARGET_C_K&gt;0,lead(KOSPI200)-TARGET_C_K,0)+\n                     if_else(TARGET_P_K-lead(KOSPI200)&gt;0,TARGET_P_K-lead(KOSPI200),0))*250000*SELL_AMT) %&gt;% \n  # 주단위 포트폴리오 손익 계산(원금 100억 가정, 당일 투자시 다음주 실현손익을 의미)\n  mutate(REVENUE=PREMIUM+INTEREST-EXERCISE) %&gt;% \n  # 거래대상 옵션이 상장되어있지 않은 경우, MMF수익만 고려\n  mutate(REVENUE=if_else(is.na(REVENUE),INTEREST,REVENUE)) %&gt;% \n  mutate(RATE=REVENUE/cash)  # 주단위 포트폴리오 수익률\n\n# 5. 비교군 포트폴리오 생성 : 월별 5% OTM 양매도 전략\noptions2 &lt;- options %&gt;% \n  filter(PROD==\"코스피200\")\n\n# 옵션 만기일(매달) 생성\ntarget_date2 &lt;- options2 %&gt;% \n  distinct(.,BAS_DD, PRIOR) %&gt;% \n  arrange(PRIOR, desc(BAS_DD)) %&gt;% \n  group_by(PRIOR) %&gt;% \n  slice(1) %&gt;% \n  ungroup() %&gt;% \n  distinct(BAS_DD) %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  filter(BAS_DD&lt;20241231, BAS_DD&gt;20200101)\n\n# 일반 양매도 포트폴리오 기본 정보 생성\ntarget_info2 &lt;- target_date2 %&gt;% \n  left_join(options2, by=\"BAS_DD\") %&gt;% \n  distinct(BAS_DD,PRIOR) %&gt;% \n  arrange(desc(BAS_DD),PRIOR) %&gt;% \n  group_by(BAS_DD) %&gt;% \n  # 만기가 도래하는 옵션을 제외하고 우선순위가 높은 옵션 선택\n  slice(2) %&gt;% \n  ungroup() %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  left_join(idx_data, by=\"BAS_DD\") %&gt;% \n  left_join(mmf_raw, by=\"BAS_DD\") %&gt;% \n  # 옵션 보유기간 및 단기금리(MMF) 계산\n  mutate(DIFF_DAY=as.integer(ymd(lag(BAS_DD))-ymd(BAS_DD)),\n         MMF=MMF*0.01,\n         VOL=0.05) %&gt;%\n  # 변동성에 따른 옵션 행사가격 상단(2.5단위 올림) 및 하단(2.5단위 내림) 계산\n  mutate(TARGET_C_K=ceiling(KOSPI200*(1+VOL)*0.4)/0.4,\n         TARGET_P_K=floor(KOSPI200*(1-VOL)*0.4)/0.4) %&gt;% \n  mutate(DIFF_DAY=if_else(is.na(DIFF_DAY),28,DIFF_DAY)) %&gt;% \n  select(BAS_DD,VOL,DIFF_DAY,MMF,KOSPI200,LAG_VK200,PRIOR,TARGET_C_K,TARGET_P_K)\n\n# 일반 양매도 포트폴리오 거래대상 옵션\ntarget_options2 &lt;- target_info2 %&gt;% \n  select(BAS_DD, PRIOR, TARGET_C_K, TARGET_P_K) %&gt;% \n  pivot_longer(cols=c(\"TARGET_C_K\",\"TARGET_P_K\"),names_to = \"GRP\", values_to = \"EXER_PRC\") %&gt;% \n  mutate(RGHT=substr(GRP,8,8)) %&gt;% \n  left_join(options2,by=c(\"BAS_DD\",\"PRIOR\",\"RGHT\",\"EXER_PRC\")) %&gt;%\n  select(BAS_DD,GRP,PRICE,ACC_TRDVOL) %&gt;% \n  pivot_wider(names_from = \"GRP\", values_from = c(\"PRICE\",\"ACC_TRDVOL\"))\n\n# 일반 양매도 포트폴리오 구현\nportfolio2 &lt;- target_info2 %&gt;% \n  left_join(target_options2,by=\"BAS_DD\") %&gt;% \n  arrange(BAS_DD) %&gt;% \n  # 원금에 따른 옵션 매도수량 계산\n  mutate(SELL_AMT=cash/250000/KOSPI200) %&gt;% \n  # 옵션 프리미엄(매도수익)) 계산\n  mutate(PREMIUM=SELL_AMT*(PRICE_TARGET_C_K+PRICE_TARGET_P_K)*250000) %&gt;% \n  # 원금 및 프리미엄의 MMF 이자수익 및 권리행사손실 계산\n  mutate(INTEREST=(cash+replace_na(PREMIUM,0))*MMF*DIFF_DAY/365,\n         EXERCISE=(if_else(lead(KOSPI200)-TARGET_C_K&gt;0,lead(KOSPI200)-TARGET_C_K,0)+\n                     if_else(TARGET_P_K-lead(KOSPI200)&gt;0,TARGET_P_K-lead(KOSPI200),0))*250000*SELL_AMT) %&gt;% \n  mutate(EXERCISE=if_else(is.na(EXERCISE),0,EXERCISE)) %&gt;% \n  # 주단위 포트폴리오 손익 계산(원금 100억 가정, 당일 투자시 다음주 실현손익을 의미)\n  mutate(REVENUE=PREMIUM+INTEREST-EXERCISE) %&gt;% \n  # 거래대상 옵션이 상장되어있지 않은 경우, MMF수익만 고려\n  mutate(REVENUE=if_else(is.na(REVENUE),INTEREST,REVENUE)) %&gt;% \n  mutate(RATE=REVENUE/cash) # 주단위 포트폴리오 수익률\n\n# 6. 성과분석 : VW양매도 포트폴리오\nperformance &lt;- portfolio %&gt;%\n  drop_na(PREMIUM, EXERCISE) %&gt;%\n  mutate(YEAR = substr(BAS_DD, 1, 4),\n         YM = ym(substr(BAS_DD, 1, 6))) %&gt;%\n  group_by(YEAR, YM) %&gt;%\n  summarise(PREMIUM = sum(PREMIUM),\n            INTEREST = sum(INTEREST),\n            EXERCISE = sum(EXERCISE),\n            REVENUE = sum(REVENUE),\n            RATE = prod(1 + RATE),\n            .groups = \"drop\") %&gt;%\n  ungroup()\n\n# 6. 성과분석 : 일반 양매도 포트폴리오\nperformance2 &lt;- portfolio2 %&gt;%\n  drop_na(PREMIUM, EXERCISE) %&gt;%\n  mutate(YEAR = substr(BAS_DD, 1, 4),\n         YM = ym(substr(BAS_DD, 1, 6))) %&gt;%\n  group_by(YEAR, YM) %&gt;%\n  summarise(PREMIUM = sum(PREMIUM),\n            INTEREST = sum(INTEREST),\n            EXERCISE = sum(EXERCISE),\n            REVENUE = sum(REVENUE),\n            RATE = prod(1 + RATE),\n            .groups = \"drop\") %&gt;%\n  ungroup()\n\n# 시각화 등\ngraph1_1 &lt;- performance %&gt;%\n  arrange(YM) %&gt;%\n  left_join(K200_portfolio,by=c(\"YEAR\",\"YM\")) %&gt;% \n  mutate(CUM_RATE = cumprod(RATE) * 100 - 100,\n         CUM_RATE_K200 = cumprod(RATE_K200) * 100 - 100) %&gt;% \n  bind_rows(tibble(YM=ym(201912),CUM_RATE=0,CUM_RATE_K200=0))\n  \n\ngraph1_2 &lt;- performance2 %&gt;%\n  arrange(YM) %&gt;%\n  left_join(K200_portfolio,by=c(\"YEAR\",\"YM\")) %&gt;% \n  mutate(CUM_RATE = cumprod(RATE) * 100 - 100,\n         CUM_RATE_K200 = cumprod(RATE_K200) * 100 - 100) %&gt;% \n  bind_rows(tibble(YM=ym(201912),CUM_RATE=0,CUM_RATE_K200=0))\n\ngraph1_3 &lt;- graph1_1 %&gt;%\n  inner_join(graph1_2, by = \"YM\", suffix = c(\"_1\", \"_2\")) %&gt;%\n  mutate(REVENUE_DIFF = (REVENUE_1 - REVENUE_2) / 1e8)\n\ngraph2_1 &lt;- performance %&gt;%\n  arrange(YM) %&gt;%\n  left_join(K200_portfolio,by=c(\"YEAR\",\"YM\")) %&gt;% \n  filter(as.integer(YEAR) &gt; 2021) %&gt;%\n  mutate(CUM_RATE = cumprod(RATE) * 100 - 100,\n         CUM_RATE_K200 = cumprod(RATE_K200) * 100 - 100) %&gt;% \n  bind_rows(tibble(YM=ym(202112),CUM_RATE=0,CUM_RATE_K200=0))\n\ngraph2_2 &lt;- performance2 %&gt;%\n  arrange(YM) %&gt;%\n  left_join(K200_portfolio,by=c(\"YEAR\",\"YM\")) %&gt;% \n  filter(as.integer(YEAR) &gt; 2021) %&gt;%\n  mutate(CUM_RATE = cumprod(RATE) * 100 - 100,\n         CUM_RATE_K200 = cumprod(RATE_K200) * 100 - 100) %&gt;% \n  bind_rows(tibble(YM=ym(202112),CUM_RATE=0,CUM_RATE_K200=0))\n\ngraph2_3 &lt;- graph2_1 %&gt;%\n  inner_join(graph2_2, by = \"YM\", suffix = c(\"_1\", \"_2\")) %&gt;%\n  mutate(REVENUE_DIFF = (REVENUE_1 - REVENUE_2) / 1e8)\n\ngraph3_1 &lt;- portfolio %&gt;%\n  mutate(YM = ym(substr(BAS_DD, 1, 6))) %&gt;%\n  group_by(YM) %&gt;%\n  summarise(TargetVol=mean(VOL),\n            Kospi200=mean(KOSPI200)) %&gt;% ungroup()\n\ngraph1=ggplot() +\n  geom_line(data = graph1_1, aes(x = YM, y = CUM_RATE, color = \"Vol-adj. Weekly\"), size = 1) +\n  geom_point(data = graph1_1, aes(x = YM, y = CUM_RATE, color = \"Vol-adj. Weekly\"), shape = 16, size = 2) +\n  geom_line(data = graph1_2, aes(x = YM, y = CUM_RATE, color = \"5% OTM Monthly\"), size = 1) +\n  geom_point(data = graph1_2, aes(x = YM, y = CUM_RATE, color = \"5% OTM Monthly\"), shape = 16, size = 2) +\n  geom_line(data = graph1_1, aes(x = YM, y = CUM_RATE_K200, color = \"Kospi 200\"), size = 1, alpha=0.7) +\n  geom_point(data = graph1_1, aes(x = YM, y = CUM_RATE_K200, color = \"Kospi 200\"), shape = 16, size = 2,alpha=0.7) +\n  geom_bar(data = graph1_3, aes(x = YM, y = REVENUE_DIFF * 3),\n           stat = \"identity\", alpha = 0.5, fill = \"gray\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  scale_y_continuous(limits = c(-30, 50), breaks = seq(-30, 50, 10), labels = scales::number_format(accuracy = 0.1),\n                     sec.axis = sec_axis(~ . / 3, name = \"Overperform (100M)\", breaks = c(-10, -5, 0, 5, 10), labels = c(\"-10\", \"-5\", \"0\", \"5\", \"10\"))) +\n  scale_color_manual(values = c(\"Vol-adj. Weekly\" = \"red\", \"5% OTM Monthly\" = \"blue\", \"Kospi 200\" = \"Green\")) +\n  labs(x = NULL, y = \"Cumulative Return (%)\", color = \"\") +\n  theme_minimal() +\n  theme(legend.position = c(0.4, 0.93), legend.direction = \"horizontal\")\n\ngraph2=ggplot() +\n  geom_line(data = graph2_1, aes(x = YM, y = CUM_RATE, color = \"Vol-adj. Weekly\"), size = 1) +\n  geom_point(data = graph2_1, aes(x = YM, y = CUM_RATE, color = \"Vol-adj. Weekly\"), shape = 16, size = 2) +\n  geom_line(data = graph2_2, aes(x = YM, y = CUM_RATE, color = \"5% OTM Monthly\"), size = 1) +\n  geom_point(data = graph2_2, aes(x = YM, y = CUM_RATE, color = \"5% OTM Monthly\"), shape = 16, size = 2) +\n  geom_line(data = graph2_1, aes(x = YM, y = CUM_RATE_K200, color = \"Kospi 200\"), size = 1, alpha=0.7) +\n  geom_point(data = graph2_1, aes(x = YM, y = CUM_RATE_K200, color = \"Kospi 200\"), shape = 16, size = 2,alpha=0.7) +\n  geom_bar(data = graph2_3, aes(x = YM, y = REVENUE_DIFF * 3),\n           stat = \"identity\", alpha = 0.5, fill = \"gray\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  scale_y_continuous(limits = c(-30, 20), breaks = seq(-30, 30, 10), labels = scales::number_format(accuracy = 0.1),\n                     sec.axis = sec_axis(~ . / 3, name = \"Overperform (100M)\", breaks = c(-10, -5, 0, 5, 10), labels = c(\"-10\", \"-5\", \"0\", \"5\", \"10\"))) +\n  scale_color_manual(values = c(\"Vol-adj. Weekly\" = \"red\", \"5% OTM Monthly\" = \"blue\", \"Kospi 200\" = \"Green\")) +\n  labs(x = NULL, y = \"Cumulative Return (%)\", color = \"\") +\n  theme_minimal() +\n  theme(legend.position = c(0.4, 0.93), legend.direction = \"horizontal\")\n\ngraph3=ggplot() +\n  geom_line(data = graph3_1, aes(x = YM, y = Kospi200, color = \"Kospi 200\"), size = 1) +\n  geom_point(data = graph3_1, aes(x = YM, y = Kospi200, color = \"Kospi 200\"), shape = 16, size = 2) +\n  geom_bar(data = graph3_1, aes(x = YM, y = TargetVol * 7000),\n           stat = \"identity\", alpha = 0.7, fill = \"blue\") +\n  geom_hline(yintercept = 200, size=0.5, color = \"black\", alpha=0.5)+\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  scale_y_continuous(limits = c(0, 500), breaks = seq(100, 500, 100),\n                     sec.axis = sec_axis(~ . / 7000, name = \"Strike Range(Monthly)\", breaks = c(0, 0.025,0.05,0.075, 0.1), labels = c(\"0\",\"5%\", \"10%\",\"15%\", \"20%\"))) +\n  scale_color_manual(values = c(\"Kospi 200\" = \"red\")) +\n  labs(x = NULL, y = \"Kospi 200\", color = \"\") +\n  theme_minimal() +\n  theme(legend.position = c(0.1, 0.93), legend.direction = \"horizontal\")\n\n# 요약표 1 : VW포트폴리오\ntable1 &lt;- portfolio %&gt;%\n  drop_na(PREMIUM, EXERCISE) %&gt;%\n  mutate(YEAR = substr(BAS_DD, 1, 4),\n         CNT=1,\n         NO=if_else(EXERCISE==0,1,0)) %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(Expiry = sum(CNT),\n            NoExercise = round(sum(NO)/sum(CNT),2),\n            Premium = round(mean(PREMIUM)/10000,0),\n            Interest = round(mean(INTEREST)/10000,0),\n            Loss = round(mean(EXERCISE)/10000,0),\n            Revenue = round(mean(REVENUE)/10000,0),\n            Return = round(prod(1 + RATE)-1,2),\n            .groups = \"drop\") %&gt;% \n  left_join(K200_portfolio %&gt;% group_by(YEAR) %&gt;% summarise(Return_K200=round(prod(RATE_K200)-1,2)),\n            by=\"YEAR\")\n\n# 요약표 2 : 일반 포트폴리오\ntable2 &lt;- portfolio2 %&gt;%\n  drop_na(PREMIUM, EXERCISE) %&gt;%\n  mutate(YEAR = substr(BAS_DD, 1, 4),\n         CNT=1,\n         NO=if_else(EXERCISE==0,1,0)) %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(Expiry = sum(CNT),\n            NoExercise = round(sum(NO)/sum(CNT),2),\n            Premium = round(mean(PREMIUM)/10000,0),\n            Interest = round(mean(INTEREST)/10000,0),\n            Loss = round(mean(EXERCISE)/10000,0),\n            Revenue = round(mean(REVENUE)/10000,0),\n            Return = round(prod(1 + RATE)-1,2),\n            .groups = \"drop\") %&gt;% \n  left_join(K200_portfolio %&gt;% group_by(YEAR) %&gt;% summarise(Return_K200=round(prod(RATE_K200)-1,2)),\n            by=\"YEAR\")\n\n# 요약표 3 : 포트폴리오 변동성 비교\nVol1 &lt;- graph1_1 %&gt;% group_by(YEAR) %&gt;% summarise(Vol=round(sd(RATE)*sqrt(12),2),\n                                                  Vol_K200=round(sd(RATE_K200)*sqrt(12),2))\nVol2 &lt;- graph1_2 %&gt;% group_by(YEAR) %&gt;% summarise(Vol=round(sd(RATE)*sqrt(12),2))\n\ntable3 &lt;- table1 %&gt;% \n  select(YEAR,Return,Return_K200) %&gt;% \n  left_join(Vol1, by=\"YEAR\") %&gt;% \n  mutate(Return_main=Return,\n         Vol_main=Vol) %&gt;% \n  select(YEAR, Return_main,Vol_main,Return_K200,Vol_K200) %&gt;% \n  left_join(table2 %&gt;% \n              select(YEAR,Return) %&gt;% \n              left_join(Vol2, by=\"YEAR\") %&gt;% \n              mutate(Return_sub=Return,\n                     Vol_sub=Vol) %&gt;% \n              select(YEAR,Return_sub,Vol_sub), by=\"YEAR\")\n\n\n\nR code 2 : 전략 검증\n\nrm(list=ls())\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(patchwork)\nsetwd(\"homepage/study_25spring/data/\")\n\n# 1. 원본데이터 준비\noptions_raw &lt;- read_csv(\"options_data_test.csv\") %&gt;% tibble()\nidx_raw &lt;- read_csv(\"idx_data_test.csv\") %&gt;% tibble()\nmmf_raw &lt;- read_csv(\"mmf_test.csv\") %&gt;% tibble()\n\n# 2-1. 데이터 전처리 : KRX openAPI 옵션데이터 전처리\noptions &lt;- options_raw %&gt;% \n  # K200, WK200 이외의 옵션 제외\n  filter(substr(PROD_NM,1,3)==\"코스피\") %&gt;%\n  # 종가가 없는 경우 익일 기준가격(이론가격) 사용\n  mutate(PRICE = as.double(if_else(TDD_CLSPRC==\"-\",NXTDD_BAS_PRC,TDD_CLSPRC))) %&gt;% \n  drop_na(PRICE) %&gt;% \n  select(BAS_DD,ISU_NM,PRICE,ACC_TRDVOL) %&gt;% \n  separate(ISU_NM, into=c(\"PROD\",\"RGHT\",\"EXP\",\"EXER_PRC\"), sep=' ') %&gt;%\n  mutate(EXER_PRC=as.double(EXER_PRC),\n         EXPMM=if_else(PROD==\"코스피200\",substr(EXP,3,6),substr(EXP,1,4)),\n         EXPWW=if_else(PROD==\"코스피200\",2,as.integer(substr(EXP,6,6)))) %&gt;% \n  filter(EXER_PRC&gt;min(idx_raw$KOSPI200)*0.85,\n         EXER_PRC&lt;max(idx_raw$KOSPI200)*1.15,\n         PROD!=\"코스피위클리M\") %&gt;% # 월요일 만기 위클리옵션 제외\n  mutate(PRIOR=as.integer(EXPMM)*10+EXPWW) # 만기가 짧은 순으로 우선순위 부여\n\n# 2-2. 데이터 전처리 : 옵션 만기일 데이터 생성\ntarget_date &lt;- options %&gt;% \n  distinct(.,BAS_DD, PRIOR) %&gt;% \n  arrange(PRIOR, desc(BAS_DD)) %&gt;% \n  group_by(PRIOR) %&gt;% \n  slice(1) %&gt;% \n  ungroup() %&gt;% \n  distinct(BAS_DD) %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  filter(BAS_DD&lt;20250411)\n\n# 2-3. 데이터 전처리 : KRX 정보데이터시스템 K200 및 V-K200지수 전처리\nidx_data &lt;- idx_raw %&gt;%\n  arrange(BAS_DD) %&gt;% \n  mutate(LAG_K200=lag(KOSPI200),\n         LAG_VK200=lag(VKOSPI200))\n\nK200_portfolio=idx_data %&gt;% \n  left_join(mmf_raw, by=\"BAS_DD\") %&gt;% \n  mutate(RATE=(KOSPI200-LAG_K200)/LAG_K200,\n         YEAR = substr(BAS_DD, 1, 4),\n         YM = ym(substr(BAS_DD, 1, 6))) %&gt;%\n  group_by(YEAR) %&gt;%\n  filter(is.na(RATE)==FALSE) %&gt;% \n  summarise(RATE_K200 = prod(1 + RATE),\n            MMF = mean(MMF)/100,\n            .groups = \"drop\") %&gt;%\n  ungroup()\n\n# 3-1. 포트폴리오 구성 : VW양매도 포트폴리오 기초정보 생성\ntarget_info &lt;- target_date %&gt;% \n  left_join(options, by=\"BAS_DD\") %&gt;% \n  distinct(BAS_DD,PRIOR) %&gt;% \n  arrange(desc(BAS_DD),PRIOR) %&gt;% \n  group_by(BAS_DD) %&gt;% \n  # 만기가 도래하는 옵션을 제외하고 우선순위가 높은 옵션 선택\n  slice(2) %&gt;% \n  ungroup() %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  left_join(idx_data, by=\"BAS_DD\") %&gt;% \n  left_join(mmf_raw, by=\"BAS_DD\") %&gt;% \n  # 옵션 보유기간 및 단기금리(MMF) 계산\n  mutate(DIFF_DAY=as.integer(ymd(lag(BAS_DD))-ymd(BAS_DD)),\n         MMF=MMF*0.01) %&gt;% \n  # 옵션 보유기간에 해당하는 시장기대변동성 계산(V-K200활용)\n  mutate(VOL=LAG_VK200*sqrt(DIFF_DAY)/sqrt(365)/100) %&gt;%\n  # 변동성에 따른 옵션 행사가격 상단(2.5단위 올림) 및 하단(2.5단위 내림) 계산\n  mutate(TARGET_C_K=ceiling(KOSPI200*(1+VOL)*0.4)/0.4,\n         TARGET_P_K=floor(KOSPI200*(1-VOL)*0.4)/0.4) %&gt;% \n  # drop_na(DIFF_DAY) %&gt;% \n  select(BAS_DD,VOL,DIFF_DAY,MMF,KOSPI200,LAG_VK200,PRIOR,TARGET_C_K,TARGET_P_K)\n\n# 3-2. 포트폴리오 구성 : VW양매도 포트폴리오 거래대상 옵션 정보 생성\ntarget_options &lt;- target_info %&gt;% \n  select(BAS_DD, PRIOR, TARGET_C_K, TARGET_P_K) %&gt;% \n  pivot_longer(cols=c(\"TARGET_C_K\",\"TARGET_P_K\"),names_to = \"GRP\", values_to = \"EXER_PRC\") %&gt;% \n  mutate(RGHT=substr(GRP,8,8)) %&gt;% \n  left_join(options,by=c(\"BAS_DD\",\"PRIOR\",\"RGHT\",\"EXER_PRC\")) %&gt;%\n  select(BAS_DD,GRP,PRICE,ACC_TRDVOL) %&gt;% \n  pivot_wider(names_from = \"GRP\", values_from = c(\"PRICE\",\"ACC_TRDVOL\"))\n\n# 원금 100억원 가정\ncash = 10000*10000*100\n\n# 4. 포트폴리오 구현 : VW양매도 전략을 구현하여 일자별 손익 계산\nportfolio &lt;- target_info %&gt;% \n  left_join(target_options,by=\"BAS_DD\") %&gt;% \n  arrange(BAS_DD) %&gt;% \n  # 원금에 따른 옵션 매도수량 계산\n  mutate(SELL_AMT=cash/250000/KOSPI200) %&gt;% \n  # 옵션 프리미엄(매도수익)) 계산\n  mutate(PREMIUM=SELL_AMT*(PRICE_TARGET_C_K+PRICE_TARGET_P_K)*250000) %&gt;% \n  # 원금 및 프리미엄의 MMF 이자수익 및 권리행사손실 계산\n  mutate(INTEREST=(cash+replace_na(PREMIUM,0))*MMF*DIFF_DAY/365,\n         EXERCISE=(if_else(lead(KOSPI200)-TARGET_C_K&gt;0,lead(KOSPI200)-TARGET_C_K,0)+\n                     if_else(TARGET_P_K-lead(KOSPI200)&gt;0,TARGET_P_K-lead(KOSPI200),0))*250000*SELL_AMT) %&gt;% \n  # 주단위 포트폴리오 손익 계산(원금 100억 가정, 당일 투자시 다음주 실현손익을 의미)\n  mutate(REVENUE=PREMIUM+INTEREST-EXERCISE) %&gt;% \n  # 거래대상 옵션이 상장되어있지 않은 경우, MMF수익만 고려\n  mutate(REVENUE=if_else(is.na(REVENUE),INTEREST,REVENUE)) %&gt;% \n  mutate(RATE=REVENUE/cash,\n         Group=\"Vol-adj. Weekly\")  # 주단위 포트폴리오 수익률\n\n# 5. 비교군 포트폴리오 생성 : 월별 5% OTM 양매도 전략\noptions2 &lt;- options %&gt;% \n  filter(PROD==\"코스피200\")\n\n# 옵션 만기일(매달) 생성\ntarget_date2 &lt;- options2 %&gt;% \n  distinct(.,BAS_DD, PRIOR) %&gt;% \n  arrange(PRIOR, desc(BAS_DD)) %&gt;% \n  group_by(PRIOR) %&gt;% \n  slice(1) %&gt;% \n  ungroup() %&gt;% \n  distinct(BAS_DD) %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  filter(BAS_DD&lt;20250411)\n\n# 일반 양매도 포트폴리오 기본 정보 생성\ntarget_info2 &lt;- target_date2 %&gt;% \n  left_join(options2, by=\"BAS_DD\") %&gt;% \n  distinct(BAS_DD,PRIOR) %&gt;% \n  arrange(desc(BAS_DD),PRIOR) %&gt;% \n  group_by(BAS_DD) %&gt;% \n  # 만기가 도래하는 옵션을 제외하고 우선순위가 높은 옵션 선택\n  slice(2) %&gt;% \n  ungroup() %&gt;% \n  arrange(desc(BAS_DD)) %&gt;% \n  left_join(idx_data, by=\"BAS_DD\") %&gt;% \n  left_join(mmf_raw, by=\"BAS_DD\") %&gt;% \n  # 옵션 보유기간 및 단기금리(MMF) 계산\n  mutate(DIFF_DAY=as.integer(ymd(lag(BAS_DD))-ymd(BAS_DD)),\n         MMF=MMF*0.01,\n         VOL=0.05) %&gt;%\n  # 변동성에 따른 옵션 행사가격 상단(2.5단위 올림) 및 하단(2.5단위 내림) 계산\n  mutate(TARGET_C_K=ceiling(KOSPI200*(1+VOL)*0.4)/0.4,\n         TARGET_P_K=floor(KOSPI200*(1-VOL)*0.4)/0.4) %&gt;% \n  mutate(DIFF_DAY=if_else(is.na(DIFF_DAY),28,DIFF_DAY)) %&gt;% \n  select(BAS_DD,VOL,DIFF_DAY,MMF,KOSPI200,LAG_VK200,PRIOR,TARGET_C_K,TARGET_P_K)\n\n# 일반 양매도 포트폴리오 거래대상 옵션\ntarget_options2 &lt;- target_info2 %&gt;% \n  select(BAS_DD, PRIOR, TARGET_C_K, TARGET_P_K) %&gt;% \n  pivot_longer(cols=c(\"TARGET_C_K\",\"TARGET_P_K\"),names_to = \"GRP\", values_to = \"EXER_PRC\") %&gt;% \n  mutate(RGHT=substr(GRP,8,8)) %&gt;% \n  left_join(options2,by=c(\"BAS_DD\",\"PRIOR\",\"RGHT\",\"EXER_PRC\")) %&gt;%\n  select(BAS_DD,GRP,PRICE,ACC_TRDVOL) %&gt;% \n  pivot_wider(names_from = \"GRP\", values_from = c(\"PRICE\",\"ACC_TRDVOL\"))\n\n# 일반 양매도 포트폴리오 구현\nportfolio2 &lt;- target_info2 %&gt;% \n  left_join(target_options2,by=\"BAS_DD\") %&gt;% \n  arrange(BAS_DD) %&gt;% \n  # 원금에 따른 옵션 매도수량 계산\n  mutate(SELL_AMT=cash/250000/KOSPI200) %&gt;% \n  # 옵션 프리미엄(매도수익)) 계산\n  mutate(PREMIUM=SELL_AMT*(PRICE_TARGET_C_K+PRICE_TARGET_P_K)*250000) %&gt;% \n  # 원금 및 프리미엄의 MMF 이자수익 및 권리행사손실 계산\n  mutate(INTEREST=(cash+replace_na(PREMIUM,0))*MMF*DIFF_DAY/365,\n         EXERCISE=(if_else(lead(KOSPI200)-TARGET_C_K&gt;0,lead(KOSPI200)-TARGET_C_K,0)+\n                     if_else(TARGET_P_K-lead(KOSPI200)&gt;0,TARGET_P_K-lead(KOSPI200),0))*250000*SELL_AMT) %&gt;% \n  mutate(EXERCISE=if_else(is.na(EXERCISE),0,EXERCISE)) %&gt;% \n  # 주단위 포트폴리오 손익 계산(원금 100억 가정, 당일 투자시 다음주 실현손익을 의미)\n  mutate(REVENUE=PREMIUM+INTEREST-EXERCISE) %&gt;% \n  # 거래대상 옵션이 상장되어있지 않은 경우, MMF수익만 고려\n  mutate(REVENUE=if_else(is.na(REVENUE),INTEREST,REVENUE)) %&gt;% \n  mutate(RATE=REVENUE/cash,\n         Group=\"Monthly\") # 주단위 포트폴리오 수익률\n\nportfolio &lt;- portfolio %&gt;% filter(BAS_DD!=20250410)\nportfolio2 &lt;- portfolio2 %&gt;% filter(BAS_DD!=20250410)\nportfolio3 &lt;- portfolio %&gt;% \n  summarise(across(where(is.numeric), sum)) %&gt;% \n  mutate(Group=\"Vol-adj. Weekly Sum\")\n  \n\n# 요약표 4 : 검증 자료\ntable4 &lt;- portfolio %&gt;%\n  union_all(portfolio2) %&gt;%\n  union_all(portfolio3) %&gt;% \n  group_by(BAS_DD, Group) %&gt;%\n  summarise(Premium = round(mean(PREMIUM)/10000,0),\n            Interest = round(mean(INTEREST)/10000,0),\n            Loss = round(mean(EXERCISE)/10000,0),\n            Revenue = round(mean(REVENUE)/10000,0),\n            Return = round(prod(1 + RATE)-1,2),\n            .groups = \"drop\")\n\n# 그래프 4 : 검증기간중 코스피200지수 추이\ngraph4 &lt;- ggplot(idx_raw, aes(x = ymd(BAS_DD))) +\n  geom_line(aes(y = KOSPI200, color = \"KOSPI200\"), size = 1.2) +\n  geom_line(aes(y = (VKOSPI200 - 19) / 26 * 60 + 300, color = \"VKOSPI200\"), size = 1.2) +\n  geom_vline(xintercept = ymd(c(\"20250313\", \"20250320\", \"20250327\", \"20250403\",\"20250410\")),\n             linetype = \"dotted\", color = \"grey40\") +\n  scale_y_continuous(name = \"KOSPI200\",limits = c(300, 360),\n                     sec.axis = sec_axis(\n                       ~ (.-300) / 60 * 26 + 19, name = \"VKOSPI200\")) +\n  scale_color_manual(values = c(\"KOSPI200\" = \"blue\", \"VKOSPI200\" = \"red\"),\n                     guide = guide_legend(direction = \"horizontal\")) +\n  labs(title = \"Kospi200 & V-Kospi200 indices\",x = NULL,color = NULL) +\n  theme_minimal() +\n  scale_x_date(date_breaks = \"3 days\", date_labels = \"%m-%d\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = c(0.5, 0.95))",
    "crumbs": [
      "사례로 보는 금융공학('25 봄)",
      "코스피200 변동성 조정 위클리 양매도 전략"
    ]
  },
  {
    "objectID": "금융윤리1.html",
    "href": "금융윤리1.html",
    "title": "금융윤리와 사회책임",
    "section": "",
    "text": "Standard 1 : Professionalism",
    "crumbs": [
      "금융윤리와 사회책임('25 봄)",
      "금융윤리와 사회책임"
    ]
  },
  {
    "objectID": "금융윤리1.html#standard-1-professionalism",
    "href": "금융윤리1.html#standard-1-professionalism",
    "title": "금융윤리와 사회책임",
    "section": "",
    "text": "A. 법규의 이해와 준수 (Knowledge of the Law)\n\n\nAssignment 1\n\n\n\n\n\nC. 오해의 소지가 있는 표현 금지 (Misrepresentation)\n\n\nAssignment 1",
    "crumbs": [
      "금융윤리와 사회책임('25 봄)",
      "금융윤리와 사회책임"
    ]
  },
  {
    "objectID": "장외파생_과제.html",
    "href": "장외파생_과제.html",
    "title": "장외파생상품 기초실무 과제",
    "section": "",
    "text": "평가 상품 개요\n이번 과제에서 평가해볼 장외파생상품은 S&P500 기반의 ELB입니다.\nLong put + 20% Knock-out 형태로, 원금보장형 payoff를 가지고 있습니다.\n세부 사항은 아래 사진과 같습니다.\n이는 배리어옵션의 한 종류로, 만기까지 한번이라도 배리어(20%) 밑으로 하락하는 경우가 존재하면 옵션 권리가 사라지고(Down-and-Out), 대신 6%의 rebate를 지급하는 구조입니다.",
    "crumbs": [
      "장외파생상품 기초 실무('25 봄)",
      "장외파생상품 기초실무 과제"
    ]
  },
  {
    "objectID": "장외파생_과제.html#mcs를-이용한-평가",
    "href": "장외파생_과제.html#mcs를-이용한-평가",
    "title": "장외파생상품 기초실무 과제",
    "section": "MCS를 이용한 평가",
    "text": "MCS를 이용한 평가\n평가 상품을 최초기준가격평가일(’25.3.19)을 기준으로 pricing할 예정이며, 배리어옵션 평가 parameter는 아래와 같이 정리하였습니다.\n\n\\(S_0\\) : S&P500지수의 ’25.3.19일 종가 (5,675.29pt)\n\\(K\\) : Down-and-out put options 행사가격(=\\(S_0\\times 100\\%\\))\n\\(B\\) : Down-and-out put options 배리어가격(=\\(S_0\\times 80\\%\\))\n\\(r\\) : 무위험이자율(=1year Term-SOFR, 4.08507%)\n\\(d\\) : S&P500 배당수익률(24년말 기준, 1.27%)\n\\(T_1\\) : 잔존만기(=1)\n\\(T_2\\) : 배리어옵션 평가대상만기(=\\(248/251\\))\n\\(n\\) : 몬테카를로 시뮬레이션 시행횟수\n\\(m\\) : 시뮬레이션 경로 분할 갯수(일별, 248)\n\n\n\n\n\n\n\n파라미터 결정 근거\n\n\n\n상품 개요에서 확인 가능한 정보로 \\(S_0,K,B,T_1\\) 결정이 가능하며,\n- 무위험이자율 : 미국에서는 SOFR, USD-libor, FFR 등이 널리 사용됩니다. 본 분석에서는 1년 만기의 기간구조를 반영하기위해 CME SOFR 선물을 활용하여 생성한 1year term SOFR를 선정하였습니다.\n- S&P500 배당수익률 : 현금배당을 연환산한 값을 사용하였으며, 과거 배당이 유지된다는 가정 하에 '24년값을 채택하였습니다.\n- 평가대상만기 : 명목 만기는 1년이나, 만기평가일에 옵션 payoff가 결정되므로, 3거래일을 차감한 값을 활용하였습니다.\n- 경로 분할 갯수 : Lookback period의 간격이 1일이므로 거래일수로 분할하였습니다.\n거래일은 NYSE를 기준으로 산출하였습니다.\n\nimport pandas_market_calendars as mcal\n\nstrt = '2025-03-20'; end='2026-03-16'; exp='2026-03-19'\nnyse = mcal.get_calendar('NYSE')\ntrd = nyse.valid_days(start_date=strt, end_date=end)\nexp = nyse.valid_days(start_date=strt, end_date=exp)\nprint(len(trd),len(exp))\n\n248 251",
    "crumbs": [
      "장외파생상품 기초 실무('25 봄)",
      "장외파생상품 기초실무 과제"
    ]
  },
  {
    "objectID": "장외파생_과제.html#평가",
    "href": "장외파생_과제.html#평가",
    "title": "장외파생상품 기초실무 과제",
    "section": "평가",
    "text": "평가\n\n평가 개요\n평가는 몬테카를로 시뮬레이션을 이용할 계획이며, Numerix pricer와 동일한 2025-4-29일을 기준으로 pricing하도록 하겠습니다.\n배리어옵션 평가를 위한 parameter는 아래와 같이 정리하였습니다.\n\n\\(S_0\\) : S&P500지수의 최초기준가격평가일(’25.3.19) 종가 (5,675.29pt)\n\\(S_1\\) : S&P500지수의 평가일(’25.4.29) 종가 (5,560.83pt)\n\\(K\\) : Down-and-out put options 행사가격(=\\(S_0\\times 100\\%\\))\n\\(B\\) : Down-and-out put options 배리어가격(=\\(S_0\\times 80\\%\\))\n\\(r\\) : 무위험이자율(=3% 가정)\n\\(q\\) : S&P500 배당수익률(=0% 가정정)\n\\(\\sigma\\) : 기초자산 변동성(=20% 가정)\n\\(T_1\\) : 잔존만기(=324/365)\n\\(T_2\\) : 배리어옵션 평가대상만기(=321/365)\n\\(n\\) : 몬테카를로 시뮬레이션 시행횟수\n\\(m\\) : 시뮬레이션 경로 분할 갯수(거래일별, 220)\n\\(rebate\\) : 배리어옵션 Knock-out 시 지급하는 쿠폰(=6%)\n\n\n\n\n\n\n\n파라미터 결정 근거\n\n\n\n상품 평가를 위한 파라미터의 산정 근거는 아래와 같습니다.\n- 기초자산가격, 행사가격, 배리어가격, 만기 등 : 상품 개요에서 확인\n\n- 무위험이자율 : 미국에서는 SOFR, USD-libor, FFR 등이 널리 사용되며, Swap rate 등을 활용해 term-structure를 구성하는 것이 가장 정밀한 방법입니다. 분석의 단순화를 위해 **3%를 가정**하였습니다.\n\n- S&P500 배당수익률 : 과거 배당이 유지된다고 가정하거나, 별도의 모델링을 통해 기간구조를 구성하는 것이 가장 정밀한 방법입니다. 분석의 단순화를 위해 **배당이 없다고 가정**하였습니다.\n\n- 평가대상만기 : 명목 만기는 1년이나, 만기평가일에 옵션 payoff가 결정되므로, 3거래일을 차감한 값을 활용하였습니다.\n\n- 기초자산 변동성 : 시장가격을 활용한 내재변동성을 이용하였으며, Local Vol 등을 통해 Surface를 구성하여 시뮬레이션 하는 것이 가장 정밀한 방법입니다. 다만, 분석의 단순화를 위해 **20%를 가정**하였습니다.\n- 경로 분할 갯수 : Lookback period의 간격이 1일이므로 거래일수로 분할하였습니다.\n거래일은 NYSE를 기준으로 산출하였고, 데이터는 yahoo finance, cme, cboe를 참고하였습니다.\n\nimport pandas_market_calendars as mcal\nfrom datetime import date\n\nexp = date(2026, 3, 19)\nstrt = date(2025, 4, 29)\nexptime = (exp - strt).days\n\nstrt = '2025-04-30'; end='2026-03-16';\nnyse = mcal.get_calendar('NYSE')\ntimesteps = nyse.valid_days(start_date=strt, end_date=end)\n\nprint(exptime, len(timesteps))\n\n324 220\n\n\n\n\n\n\n평가 알고리즘\n기초자산인 S&P500 지수가 GBM을 따른다는 가정 하에 정규난수를 이용하여 만기평가일까지의 주가흐름을 시뮬레이션할 계획이며, 알고리즘은 아래와 같습니다.\n\n현재 주가(\\(S_0\\))와 만기(\\(T_2\\)), 변동성(\\(\\sigma\\)), 기대수익률(\\(\\mu=r-d\\))를 통해 GBM을 구성하고, Euler’s discretization을 통해 248거래일마다 종가를 생성\n\n먼저, 평가대상만기일의 종가를 n개 생성(Stratified sampling, Moment matching, Antithetic variate를 활용하여 균질한 분포를 구현)\n각 n개의 종가마다, 그 경로의 247(총 (m-1)*n)개의 난수를 생성(Antithetic variate 적용)하고, brownian bridge 방법을 통해 오일러 이산화를 구현\n\n각 경로마다 Knock 여부와 내재가치를 고려하여 배리어옵션의 payoff와 npv를 결정\n\nKnock-out 발생 : 명목금액의 6%의 rebate를 지급받음\nKnock-out 미발생 : 평가만기일 종가에 따라 풋옵션 내재가치를 지급받음\n각 payoff를 잔존만기(\\(T_1\\))에 대해 할인하여 npv를 산출\n\n이에 따라 산출된 npv를 산술평균을 통해 배리어옵션(ELB)의 공정가치를 산출\n\n\n\n알고리즘 구현 (Python code)\n알고리즘을 Python 코드로 구현하였으며, Down-out Put option 가격과 GBM을 활용한 기초자산의 경로를 반환하는 함수로 작성하였습니다.\n\nimport numpy as np\nimport scipy.stats as sst\n\ndef DownAndOutPut_Price(s, k, r, q, t, sigma, n, b, m, rebate):\n    # Set parameters\n    dt = t/m\n    dts = np.arange(dt, t+dt, dt)\n\n    # (1) Stratified sampling, z_t makes price at T & z makes brownian bridge\n    z_t = sst.norm.ppf((np.arange(n) + np.random.uniform(0,1,n)) / n)\n    z = np.random.randn(n,m)\n    # (2) Moment matching in z_t\n    z_t = np.where(n&gt;=100, (z_t - z_t.mean()) / z_t.std(ddof=1), z_t - z_t.mean())\n    # (3) Antithetic variate\n    z_t, z = np.concatenate([z_t, -z_t], axis=0), np.concatenate([z, -z], axis=0)\n\n    # Generate underlying paths using brownian bridge\n    w_t, w = z_t * np.sqrt(t), z.cumsum(axis=1) * np.sqrt(dt) # winner process\n    bridge = dts * ((w_t- w[:,-1]).reshape(len(w),1) + w / dts) # brownian bridge\n    paths = s*np.exp((r-q-0.5*sigma**2)*dts + sigma*bridge) # underlying price path\n    # Determine whether barrier touch or not (exists payoff or not)\n    knock = paths.min(axis=1) &lt; b # knock-out = 1 else 0\n    barrier_flag = ~knock\n\n    # Caculate options payoff\n    plain_npv = np.maximum(k-paths[:,-1], 0) * np.exp(-r*t)\n    barrier_npv = barrier_flag * plain_npv + knock * rebate * np.exp(-r*t)\n    barrier_price = barrier_npv.mean()\n\n    return barrier_price, paths",
    "crumbs": [
      "장외파생상품 기초 실무('25 봄)",
      "장외파생상품 기초실무 과제"
    ]
  },
  {
    "objectID": "장외파생_과제.html#평가-결과-및-비교numerix-pricer",
    "href": "장외파생_과제.html#평가-결과-및-비교numerix-pricer",
    "title": "장외파생상품 기초실무 과제",
    "section": "평가 결과 및 비교(Numerix Pricer)",
    "text": "평가 결과 및 비교(Numerix Pricer)\n\n배리어옵션 가격 및 기초자산 경로\n상술한 2025-4-29일의 기준 파라미터를 이용하여 배리어옵션의 가격을 평가해보았습니다.\n가격은 명목금액 10,000원을 기준으로 약 365원이며, 수익률로 환산할 때 약 3.65%입니다.\n시뮬레이션 횟수는 10만번 기준으로, 난수에 따라 편차가 약 1~2원 존재하였습니다.\n\ns0 = 5675.29\ns1 = 5560.83\nk = s0\nr = 0.03\nq = 0\nb = 0.8 * s0\nt1 = exptime / 365\nt2 = (exptime-3) / 365\nsigma = 0.2\nn = 100000\nm = len(timesteps)\nrebate = 0.06 * s0\nnotional = 10000\nnxprice = 366.8977875\n\nprice, GBMpath = DownAndOutPut_Price(s1, k, r, q, t2, sigma, n, b, m, rebate)\nprice = price * np.exp(r*(t2-t1)) / s0 * notional\nprint(price)\n\n364.26567636897414\n\n\n시뮬레이션에 이용된 기초자산의 경로를 시각화한 결과입니다.\n계층화, 표준화 등 분산감소기법이 잘 적용되어 만기시점의 Lognormal dist. 형태가 잘 나타난 것을 볼 수 있으며, 시뮬레이션 중 배리어가격 밑으로 하락한 경우가 발생한 Knock-out의 비율은 약 22.65%로 나타났습니다.\n\n\n\n\n\n\n\n\n\n\n\nNumerix Pricer와 비교\n유사한 조건의 Numerix pricer를 이용한 배리어옵션 가격은 약 366.9원(3.67%)로 산출되었습니다.",
    "crumbs": [
      "장외파생상품 기초 실무('25 봄)",
      "장외파생상품 기초실무 과제"
    ]
  }
]